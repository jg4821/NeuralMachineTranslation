{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import io\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "import itertools\n",
    "import glob\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "# from sacrebleu import corpus_bleu\n",
    "# import sacrebleu\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "words_to_load = 100000\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_token = 2\n",
    "UNK_token = 3\n",
    "LR_RATE = 0.001\n",
    "MAX_LENGTH = 40\n",
    "hidden_size = 300\n",
    "teacher_forcing_ratio = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Preprocess Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"<pad>\", 3: \"<unk>\"}\n",
    "        self.n_words = 4  # Count SOS, EOS, pad and unk\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def normalizeZh(s):\n",
    "    s = s.strip()\n",
    "    s = re.sub(\"\\s+\", \" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterPair(p):\n",
    "    filtered = []\n",
    "    for i in p:\n",
    "        filtered.append(' '.join(i.split()[:MAX_LENGTH-1]))\n",
    "    return filtered\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [filterPair(pair) for pair in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readLangs(dataset, lang1, lang2):\n",
    "    chinese = os.getcwd()+'/iwslt-zh-en/{}.tok.{}'.format(dataset, lang1)\n",
    "    english = os.getcwd()+'/iwslt-zh-en/{}.tok.{}'.format(dataset, lang2)\n",
    "\n",
    "    chinese_lines = open(chinese, encoding='utf-8').read().strip().split('\\n')\n",
    "    english_lines = open(english, encoding='utf-8').read().strip().split('\\n')\n",
    "    length = len(chinese_lines)\n",
    "\n",
    "    pairs = [[normalizeZh(chinese_lines[i]), normalizeString(english_lines[i])] for i in range(length)]\n",
    "    pairs = filterPairs(pairs)\n",
    "    \n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input_lang, train_output_lang, train_pairs = readLangs('train', 'zh', 'en')\n",
    "val_input_lang, val_output_lang, val_pairs = readLangs('dev', 'zh', 'en')\n",
    "test_input_lang, test_output_lang, test_pairs = readLangs('test', 'zh', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86903"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49924"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213376"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pairs)  # 6621 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1261"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_pairs)  # 39 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1397"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Embedding__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_embedding(ft_path, words_to_load):\n",
    "    fin = io.open(ft_path, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    vocab_size = words_to_load + 4\n",
    "    embedding_dim = d\n",
    "\n",
    "    embedding_mat = np.zeros((vocab_size, embedding_dim))\n",
    "    token2id = {}\n",
    "    id2token = {}\n",
    "    all_tokens = ['SOS', 'EOS', '<unk>', '<pad>']\n",
    "\n",
    "    for i, line in enumerate(fin):\n",
    "        if i >= words_to_load:\n",
    "            break\n",
    "        s = line.rstrip().split(' ')\n",
    "        embedding_mat[i+4, :] = np.asarray(s[1:])\n",
    "        token2id[s[0]] = i+4\n",
    "        id2token[i+4] = s[0]\n",
    "        all_tokens.append(s[0])\n",
    "\n",
    "    token2id['<pad>'] = PAD_token \n",
    "    token2id['<unk>'] = UNK_token\n",
    "    token2id['SOS'] = SOS_token\n",
    "    token2id['EOS'] = EOS_token\n",
    "    id2token[PAD_token] = '<pad>'\n",
    "    id2token[UNK_token] = '<unk>'\n",
    "    id2token[SOS_token] = 'SOS'\n",
    "    id2token[EOS_token] = 'EOS'\n",
    "    embedding_mat[PAD_token, :] = np.zeros((1,d))\n",
    "    #generate normal dist 1d array for UNK, SOS, EOS token\n",
    "    embedding_mat[UNK_token, :] = np.random.normal(size=d)\n",
    "    embedding_mat[SOS_token, :] = np.random.normal(size=d)\n",
    "    embedding_mat[EOS_token, :] = np.random.normal(size=d)\n",
    "        \n",
    "    return embedding_mat, all_tokens, token2id, id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_zh = os.getcwd()+'/wiki.zh.vec'\n",
    "fname_eng = '/'.join(os.getcwd().split('/')[:-1])+'/hw2/wiki-news-300d-1M.vec'\n",
    "embedding_mat_zh, all_tokens_zh, token2id_zh, id2token_zh = load_embedding(fname_zh, words_to_load)\n",
    "embedding_mat_en, all_tokens_en, token2id_en, id2token_en = load_embedding(fname_eng, words_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100004, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_mat_zh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100004, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_mat_en.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Loader__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_lang, output_lang, pairs):\n",
    "        \"\"\"\n",
    "        @param data_list_1: list of sentence 1 tokens \n",
    "        @param data_list_2: list of sentence 2 tokens\n",
    "        @param target_list: list of review targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.input_w2i = input_lang\n",
    "        self.output_w2i = output_lang\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        input_sentence = self.pairs[key][0]\n",
    "        input_indexes = [self.input_w2i[word] if word in self.input_w2i else UNK_token for word in input_sentence.split(' ')]\n",
    "        input_indexes.append(EOS_token)\n",
    "        input_length = len(input_indexes)\n",
    "\n",
    "        output_sentence = self.pairs[key][1]\n",
    "        output_indexes = [self.output_w2i[word] if word in self.output_w2i else UNK_token for word in output_sentence.split(' ')]\n",
    "        output_indexes.append(EOS_token)\n",
    "        output_length = len(output_indexes)\n",
    "        return [input_indexes, input_length, output_indexes, output_length]\n",
    "\n",
    "    \n",
    "def NMTDataset_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    input_ls = []\n",
    "    output_ls = []\n",
    "    input_length_ls = []\n",
    "    output_length_ls = []\n",
    "    \n",
    "    for datum in batch:\n",
    "        input_length_ls.append(datum[1])\n",
    "        output_length_ls.append(datum[3])\n",
    "    \n",
    "    #find max length in each batch\n",
    "    max_input = sorted(input_length_ls)[-1]\n",
    "    max_output = sorted(output_length_ls)[-1]\n",
    "    \n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec_input = np.pad(np.array(datum[0]), \n",
    "                                  pad_width=((0,MAX_LENGTH-datum[1])), \n",
    "                                  mode=\"constant\", constant_values=2).tolist()\n",
    "        padded_vec_output = np.pad(np.array(datum[2]), \n",
    "                                   pad_width=((0,MAX_LENGTH-datum[3])), \n",
    "                                   mode=\"constant\", constant_values=2).tolist()\n",
    "        input_ls.append(padded_vec_input)\n",
    "        output_ls.append(padded_vec_output)\n",
    "    return [torch.tensor(torch.from_numpy(np.array(input_ls)), device=device), \n",
    "            torch.tensor(input_length_ls, device=device), \n",
    "            torch.tensor(torch.from_numpy(np.array(output_ls)), device=device), \n",
    "            torch.tensor(output_length_ls, device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create pytorch dataloader\n",
    "train_dataset = NMTDataset(token2id_zh, token2id_en, train_pairs)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size,\n",
    "                                           collate_fn=NMTDataset_collate_func,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)\n",
    "\n",
    "val_dataset = NMTDataset(token2id_zh, token2id_en, val_pairs)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         collate_fn=NMTDataset_collate_func,\n",
    "                                         shuffle=False,\n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 40])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(val_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in val_loader:\n",
    "#     print(i)\n",
    "    if i[0].shape[1] != 40:\n",
    "        print(True)\n",
    "#     print(i[0].shape)\n",
    "#     for ind in i[2]:\n",
    "#         for token in ind:\n",
    "#             print(token)\n",
    "#             print(train_output_lang.index2word[token.item()])\n",
    "#     for ind in i[2]:\n",
    "#         print(' '.join(train_output_lang.index2word[token.item()] for token in ind))\n",
    "#     print([train_output_lang.index2word[token.item()] for ind in i[2] for token in ind])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Encoder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        embed_mat = torch.from_numpy(embedding_mat_zh).float()\n",
    "        n, embed_dim = embed_mat.shape\n",
    "#         mask = np.zeros((n,1))\n",
    "#         mask[0] = 1\n",
    "#         mask[1] = 1\n",
    "#         mask[2] = 1\n",
    "#         mask[3] = 1\n",
    "#         mask = torch.from_numpy(mask).float()\n",
    "#         self.mask_embedding = nn.Embedding.from_pretrained(mask, freeze = False)\n",
    "        self.embedding = nn.Embedding.from_pretrained(embed_mat, freeze = True)\n",
    "        \n",
    "#         self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_size, batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, input, input_len, hidden):        \n",
    "        # get embedding of characters\n",
    "        embed = self.embedding(input)\n",
    "#         mask = self.mask_embedding(input)\n",
    "        \n",
    "#         embedded = mask*embed + (1-mask)*embed.clone().detach()\n",
    "        embedded = embed\n",
    "#         output, hidden = self.gru(embedded, hidden)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return (torch.zeros(2, batch_size, self.hidden_size, device=device),\n",
    "                torch.zeros(2, batch_size, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers=1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers \n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        embed_mat = torch.from_numpy(embedding_mat_zh).float()\n",
    "        n, embed_dim = embed_mat.shape\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(embed_mat, freeze=True)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "\n",
    "#         self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embed = self.embedding(input)\n",
    "        embed = self.dropout(embed)   \n",
    "        \n",
    "        hidden_reshaped = [h.view(hidden[0].size()[1],1,-1) for h in hidden]\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embed, hidden_reshaped[0]), 2)), dim=2)\n",
    "        \n",
    "#         pdb.set_trace()\n",
    "#         print(attn_weights.size())\n",
    "#         print(encoder_outputs.size())\n",
    "        attn_applied = torch.bmm(attn_weights, encoder_outputs).squeeze(1)\n",
    "        \n",
    "        output = torch.cat((embed.squeeze(1), attn_applied), 1)\n",
    " \n",
    "        output = self.attn_combine(output).unsqueeze(1)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        \n",
    "#         pdb.set_trace()\n",
    "        hidden_reshaped = [h.view(1,h.size()[0],-1) for h in hidden_reshaped]\n",
    "        output, hidden = self.lstm(output, hidden_reshaped)\n",
    "        output = self.softmax(self.out(output.squeeze(1)))\n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self,batch_size):\n",
    "        return torch.randn(self.num_layers, batch_size, self.hidden_size,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class Attn(nn.Module):\n",
    "#     def __init__(self, method, hidden_size):\n",
    "#         super(Attn, self).__init__()\n",
    "#         self.method = method\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "#         self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "#         stdv = 1. / math.sqrt(self.v.size(0))\n",
    "#         self.v.data.normal_(mean=0, std=stdv)\n",
    "\n",
    "#     def forward(self, hidden, encoder_outputs, src_len=None):\n",
    "#         '''\n",
    "#         :param hidden: \n",
    "#             previous hidden state of the decoder, in shape (layers*directions,B,H)\n",
    "#         :param encoder_outputs:\n",
    "#             encoder outputs from Encoder, in shape (T,B,H)\n",
    "#         :param src_len:\n",
    "#             used for masking. NoneType or tensor in shape (B) indicating sequence length\n",
    "#         :return\n",
    "#             attention energies in shape (B,T)\n",
    "#         '''\n",
    "#         max_len = encoder_outputs.size(1)\n",
    "#         this_batch_size = encoder_outputs.size(1)\n",
    "#         H = hidden.repeat(max_len,1,1).transpose(0,1)\n",
    "# #         encoder_outputs = encoder_outputs.transpose(0,1) # [B*T*H]\n",
    "#         attn_energies = self.score(H,encoder_outputs) # compute attention score\n",
    "        \n",
    "#         if src_len is not None:\n",
    "#             mask = []\n",
    "#             for b in range(src_len.size(0)):\n",
    "#                 mask.append([0] * src_len[b].item() + [1] * (encoder_outputs.size(1) - src_len[b].item()))\n",
    "#             mask = cuda_(torch.ByteTensor(mask).unsqueeze(1)) # [B,1,T]\n",
    "#             attn_energies = attn_energies.masked_fill(mask, -1e18)\n",
    "        \n",
    "#         return F.softmax(attn_energies, dim = 1).unsqueeze(1) # normalize with softmax\n",
    "\n",
    "#     def score(self, hidden, encoder_outputs):\n",
    "#         energy = torch.tanh(self.attn(torch.cat([hidden, encoder_outputs], 2))) # [B*T*2H]->[B*T*H]\n",
    "#         energy = energy.transpose(2,1) # [B*H*T]\n",
    "#         v = self.v.repeat(encoder_outputs.data.shape[0],1).unsqueeze(1) #[B*1*H]\n",
    "#         energy = torch.bmm(v,energy) # [B*1*T]\n",
    "#         return energy.squeeze(1) #[B*T]\n",
    "\n",
    "# class BahdanauAttnDecoderRNN(nn.Module):\n",
    "#     def __init__(self, weights_matrix, hidden_size, embed_size, output_size, dropout_p=0.5):\n",
    "#         super(BahdanauAttnDecoderRNN, self).__init__()\n",
    "#         # Define parameters\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.embed_size = embed_size\n",
    "#         self.output_size = output_size\n",
    "#         self.dropout_p = dropout_p\n",
    "#         # Define layers\n",
    "        \n",
    "#         embed_mat = torch.from_numpy(weights_matrix).float()\n",
    "#         self.num_embeddings, self.embedding_dim = embed_mat.shape\n",
    "#         mask = np.zeros((self.num_embeddings,1))\n",
    "#         mask[0] = 1\n",
    "#         mask[1] = 1\n",
    "#         mask[2] = 1\n",
    "#         mask[3] = 1\n",
    "#         mask = torch.from_numpy(mask).float()\n",
    "#         self.mask_embedding = nn.Embedding.from_pretrained(mask, freeze = False)\n",
    "#         self.embedding = nn.Embedding.from_pretrained(embed_mat, freeze = True)\n",
    "#         self.dropout = nn.Dropout(dropout_p)\n",
    "#         self.attn = Attn('concat', hidden_size)\n",
    "#         self.gru = nn.GRU(hidden_size + self.embedding_dim, hidden_size, dropout=dropout_p)\n",
    "#         #self.attn_combine = nn.Linear(hidden_size + embed_size, hidden_size)\n",
    "#         self.out = nn.Linear(hidden_size, self.output_size)\n",
    "\n",
    "#     def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "#         '''\n",
    "#         :param word_input:\n",
    "#             word input for current time step, in shape (B)\n",
    "#         :param last_hidden:\n",
    "#             last hidden stat of the decoder, in shape (layers*direction*B*H)\n",
    "#         :param encoder_outputs:\n",
    "#             encoder outputs in shape (T*B*H)\n",
    "#         :return\n",
    "#             decoder output\n",
    "#         Note: we run this one step at a time i.e. you should use a outer loop \n",
    "#             to process the whole sequence\n",
    "#         Tip(update):\n",
    "#         EncoderRNN may be bidirectional or have multiple layers, so the shape of hidden states can be \n",
    "#         different from that of DecoderRNN\n",
    "#         You may have to manually guarantee that they have the same dimension outside this function,\n",
    "#         e.g, select the encoder hidden state of the foward/backward pass.\n",
    "#         '''\n",
    "#         # Get the embedding of the current input word (last output word)\n",
    "#         embed = self.embedding(word_input)\n",
    "#         mask = self.mask_embedding(word_input)\n",
    "        \n",
    "#         word_embedded = mask*embed + (1-mask)*embed.clone().detach()\n",
    "#         word_embedded = self.embedding(word_input).view(word_input.size(0), 1, -1) # (1,B,V)\n",
    "#         word_embedded = self.dropout(word_embedded)\n",
    "#         # Calculate attention weights and apply to encoder outputs\n",
    "#         attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
    "#         context = attn_weights.bmm(encoder_outputs)  # (B,1,V)\n",
    "# #         context = context.transpose(0, 1)  # (1,B,V)\n",
    "#         # Combine embedded input word and attended context, run through RNN\n",
    "#         rnn_input = torch.cat((word_embedded, context), 2)\n",
    "#         #rnn_input = self.attn_combine(rnn_input) # use it in case your size of rnn_input is different\n",
    "#         output, hidden = self.gru(rnn_input.transpose(0, 1), last_hidden)\n",
    "#         output = output.squeeze(0)  # (1,B,V)->(B,V)\n",
    "#         # context = context.squeeze(0)\n",
    "#         # update: \"context\" input before final layer can be problematic.\n",
    "#         # output = F.log_softmax(self.out(torch.cat((output, context), 1)))\n",
    "#         output = F.log_softmax(self.out(output), dim = 1)\n",
    "#         # Return final output, hidden state\n",
    "#         return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input, input_len, target, target_len = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.500384521484374"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder_hidden_size = int(hidden_size/2)\n",
    "# encoder = EncoderRNN(encoder_hidden_size).to(device)\n",
    "# attn_decoder = AttnDecoderRNN(hidden_size, embedding_mat_zh.shape[0]).to(device)\n",
    "# encoder_optimizer = optim.Adam(encoder.parameters(), lr=LR_RATE)\n",
    "# decoder_optimizer = optim.Adam(attn_decoder.parameters(), lr=LR_RATE)\n",
    "# criterion = nn.NLLLoss()\n",
    "\n",
    "# #UNCOMMENT TO TRAIN THE MODEL\n",
    "# train(input, target, input_len, target_len, encoder, attn_decoder, encoder_optimizer, decoder_optimizer, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(input, target, input_len, target_len, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, teach_forcing_ratio=0.9, encoder_cnn = False):\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    max_input_len = max(input_len)\n",
    "    max_target_len = max(target_len)\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    if not encoder_cnn:\n",
    "        encoder_hidden = encoder.initHidden(batch_size)\n",
    "        encoder_output, encoder_hidden = encoder(input, input_len, encoder_hidden)\n",
    "    else:\n",
    "        encoder_hidden = encoder(input)\n",
    "        \n",
    "    decoder_input = torch.tensor([[SOS_token]]*batch_size, device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(max_target_len):\n",
    "#             decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "            loss += criterion(decoder_output, target[:,di])\n",
    "            decoder_input = target[:,di].unsqueeze(1)  # Teacher forcing (batch_size, 1)\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(max_target_len):\n",
    "#             decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "            loss += criterion(decoder_output, target[:,di])\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach().unsqueeze(1)  # detach from history as input\n",
    "    #         if decoder_input.item() == EOS_token:\n",
    "    #             break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / float(max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(loader, encoder, decoder, n_iters, encoder_cnn, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    train_loss_list = 0  # record print_loss_avg\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    best_bleu = None\n",
    "    save_path = os.getcwd() + '/saved_model/En-RNN-De-Attn-LSTM.pt'\n",
    "            \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        for i, (input, input_len, target, target_len) in enumerate(train_loader):\n",
    "            loss = train(input, target, input_len, target_len, encoder, decoder, \n",
    "                         encoder_optimizer, decoder_optimizer, criterion, \n",
    "                         teach_forcing_ratio=teacher_forcing_ratio, encoder_cnn = encoder_cnn)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "            \n",
    "            \n",
    "            if i % print_every == 0:\n",
    "                current_bleu = test(encoder, decoder, val_loader, encoder_cnn)\n",
    "                if not best_bleu or current_bleu > best_bleu:\n",
    "                    torch.save({\n",
    "                                'epoch': iter,\n",
    "                                'encoder_state_dict': encoder.state_dict(),\n",
    "                                'decoder_state_dict': decoder.state_dict(),\n",
    "                                'encoder_optimizer_state_dict': encoder_optimizer.state_dict(),\n",
    "                                'decoder_optimizer_state_dict': decoder_optimizer.state_dict(),\n",
    "                                'train_loss': loss,\n",
    "                                'best_BLEU': best_bleu\n",
    "                                }, save_path)\n",
    "                    best_bleu = current_bleu\n",
    "                \n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                train_loss_list.append(print_loss_avg)\n",
    "                print('%s (Epoch: %d %d%%) | Train Loss: %.4f | Best Bleu: %.4f | Current Bleu: %.4f' \n",
    "                      % (timeSince(start, iter / n_iters), iter, iter / n_iters * 100, print_loss_avg, best_bleu, current_bleu))\n",
    "                with open('En-RNN-De-Attn-LSTM.txt','a') as file:\n",
    "                    file.write('%s (Epoch: %d %d%%) | Train Loss: %.4f | Best Bleu: %.4f | Current Bleu: %.4f' \n",
    "                      % (timeSince(start, iter / n_iters), iter, iter / n_iters * 100, print_loss_avg, best_bleu, current_bleu))\n",
    "                \n",
    "            if i % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "    pkl.dump(train_loss_list, open('lstm_train_loss.p', 'wb'))\n",
    "#     showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, input, input_len, encoder_cnn):\n",
    "    with torch.no_grad():\n",
    "#         for i, (input, input_len, target, target_len) in enumerate(data_loader):\n",
    "        max_input_len = max(input_len)\n",
    "\n",
    "        if not encoder_cnn:\n",
    "            encoder_hidden = encoder.initHidden(batch_size)\n",
    "            encoder_output, encoder_hidden = encoder(input, input_len, encoder_hidden)\n",
    "        else:\n",
    "            encoder_hidden = encoder(input)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]]*batch_size, device=device)\n",
    "        decoder_hidden = encoder_hidden # decoder starts from the last encoding sentence\n",
    "\n",
    "        # output of this function\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_input_len):\n",
    "            # for each time step, the decoder network takes two inputs: previous outputs and the previous hidden states\n",
    "#             decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            \n",
    "#             pdb.set_trace()\n",
    "\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoded_words.append(topi.cpu().numpy())\n",
    "            decoder_input = topi.squeeze().detach().unsqueeze(1)  # detach from history as input\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        return np.asarray(decoded_words).T#, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(encoder, decoder, data_loader, encoder_cnn):\n",
    "    total_score = 0\n",
    "    count = 0\n",
    "    check = 0\n",
    "    \n",
    "    candidate_corpus = []\n",
    "    reference_corpus = []\n",
    "\n",
    "    for i, (input, input_len, target, target_len) in enumerate(data_loader):\n",
    "        decoded_words = evaluate(encoder, decoder, input, input_len, encoder_cnn)\n",
    "        candidate_sentences = []\n",
    "        for ind in range(decoded_words.shape[1]):\n",
    "            sent_words = []\n",
    "            for token in decoded_words[0][ind]:\n",
    "                if token != PAD_token and token != EOS_token:\n",
    "                    sent_words.append(id2token_en[token])\n",
    "                else:\n",
    "                    break\n",
    "            sent_words = ' '.join(sent_words)\n",
    "            if check == 0:\n",
    "                print('predict: '+sent_words)\n",
    "                check += 1\n",
    "            candidate_sentences.append(sent_words)\n",
    "#         candidate_corpus.extend(candidate_sentences)\n",
    "\n",
    "        reference_sentences = []\n",
    "        for sent in target:\n",
    "            sent_words = []\n",
    "            for token in sent:\n",
    "                if token.item() != EOS_token:\n",
    "                    sent_words.append(id2token_en[token.item()])\n",
    "                else:\n",
    "                    break\n",
    "            sent_words = ' '.join(sent_words)\n",
    "            if check == 1:\n",
    "                print('target: '+sent_words)\n",
    "                check += 1\n",
    "            reference_sentences.append(sent_words)\n",
    "#         reference_corpus.extend(reference_sentences)\n",
    "        count += 1\n",
    "        score = corpus_bleu(candidate_sentences, [reference_sentences], smooth='exp', smooth_floor=0.0, force=False).score\n",
    "        total_score += score\n",
    "    return total_score / float(count)\n",
    "\n",
    "#     score = corpus_bleu(candidate_sentences, [reference_sentences], smooth='exp', smooth_floor=0.0, force=False).score\n",
    "#     return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: Bathurst\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "0m 6s (- 1m 0s) (Epoch: 1 10%) | Train Loss: 0.1156 | Best Bleu: 0.0000 | Current Bleu: 0.0000\n",
      "predict: <unk> <unk> <unk> <unk> <unk>\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "0m 38s (- 5m 43s) (Epoch: 1 10%) | Train Loss: 4.0556 | Best Bleu: 2.9992 | Current Bleu: 2.9992\n",
      "predict: and <unk> <unk> <unk> <unk>\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "1m 9s (- 10m 27s) (Epoch: 1 10%) | Train Loss: 3.4049 | Best Bleu: 3.3395 | Current Bleu: 3.3395\n",
      "predict: and <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "1m 41s (- 15m 13s) (Epoch: 1 10%) | Train Loss: 3.2401 | Best Bleu: 3.4635 | Current Bleu: 3.4635\n",
      "predict: and <unk> <unk> <unk> <unk> <unk> <unk> <unk> . . . . .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "2m 12s (- 19m 48s) (Epoch: 1 10%) | Train Loss: 3.2383 | Best Bleu: 3.4635 | Current Bleu: 2.6008\n",
      "predict: and <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> . . . .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "2m 42s (- 24m 22s) (Epoch: 1 10%) | Train Loss: 3.1725 | Best Bleu: 3.4635 | Current Bleu: 2.1356\n",
      "predict: and <unk> <unk> the <unk> . . . . . . .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "3m 14s (- 29m 9s) (Epoch: 1 10%) | Train Loss: 3.1763 | Best Bleu: 4.0347 | Current Bleu: 4.0347\n",
      "predict: and <unk> s <unk> s the <unk> s the <unk> s the . . . .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "3m 46s (- 33m 55s) (Epoch: 1 10%) | Train Loss: 3.1475 | Best Bleu: 4.2987 | Current Bleu: 4.2987\n",
      "predict: and <unk> s <unk> s the <unk> s the <unk> s the\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "4m 17s (- 38m 40s) (Epoch: 1 10%) | Train Loss: 3.0490 | Best Bleu: 4.3150 | Current Bleu: 4.3150\n",
      "predict: and <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> . <unk> .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "4m 48s (- 43m 17s) (Epoch: 1 10%) | Train Loss: 3.0675 | Best Bleu: 4.3150 | Current Bleu: 3.0743\n",
      "predict: and i <unk> s <unk> to <unk> <unk> the <unk> . the <unk> .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "5m 20s (- 48m 3s) (Epoch: 1 10%) | Train Loss: 3.0202 | Best Bleu: 4.8719 | Current Bleu: 4.8719\n",
      "predict: and <unk> <unk> the the the <unk> the the <unk> the . .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "5m 52s (- 52m 48s) (Epoch: 1 10%) | Train Loss: 3.0367 | Best Bleu: 5.0155 | Current Bleu: 5.0155\n",
      "predict: i <unk> s to the <unk> <unk> <unk> <unk> <unk> <unk> .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "6m 24s (- 57m 37s) (Epoch: 1 10%) | Train Loss: 3.0491 | Best Bleu: 5.2311 | Current Bleu: 5.2311\n",
      "predict: i i <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "6m 54s (- 62m 11s) (Epoch: 1 10%) | Train Loss: 2.9264 | Best Bleu: 5.2311 | Current Bleu: 4.0658\n",
      "predict: i <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "7m 25s (- 66m 45s) (Epoch: 1 10%) | Train Loss: 2.9128 | Best Bleu: 5.2311 | Current Bleu: 5.0398\n",
      "predict: i <unk> m to the <unk> <unk> i <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "7m 55s (- 71m 18s) (Epoch: 1 10%) | Train Loss: 2.8819 | Best Bleu: 5.2311 | Current Bleu: 3.2552\n",
      "predict: i <unk> ve to <unk> i <unk> <unk> i <unk> <unk> <unk> <unk> .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "8m 25s (- 75m 50s) (Epoch: 1 10%) | Train Loss: 2.8610 | Best Bleu: 5.2311 | Current Bleu: 4.5718\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(hidden_size=hidden_size).to(device)\n",
    "# encoder = EncoderCNN(hidden_size,kernel_dim=3,batch_size=batch_size).to(device)\n",
    "# noattn_decoder = DecoderRNN(hidden_size, embedding_mat_zh.shape[0]).to(device)\n",
    "attn_decoder = AttnDecoderRNN(hidden_size, embedding_mat_zh.shape[0]).to(device)\n",
    "# attn_decoder1 = BahdanauAttnDecoderRNN(hidden_size, output_lang.n_words, n_layers=1, dropout_p=0.1).to(device)\n",
    "\n",
    "#UNCOMMENT TO TRAIN THE MODEL\n",
    "trainIters(train_loader, encoder, attn_decoder, n_iters=10, encoder_cnn=False, print_every=100, plot_every=1, learning_rate=LR_RATE)\n",
    "# trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\n",
    "\n",
    "# encoder.load_state_dict(torch.load(\"encoder.pth\"))\n",
    "# attn_decoder1.load_state_dict(torch.load(\"attn_decoder.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_bleu(sys_stream, ref_streams, smooth='exp', smooth_floor=0.0, force=False, lowercase=False,\n",
    "                tokenize=DEFAULT_TOKENIZER, use_effective_order=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.35533905932737\n"
     ]
    }
   ],
   "source": [
    "ref = [['this is   test']]\n",
    "candidates = ['this is a test']\n",
    "# score = sacrebleu.corpus_bleu(ref,candidates)\n",
    "score = sacrebleu.corpus_bleu(candidates,ref)\n",
    "print(score.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = os.getcwd() + '/saved_model/En-RNN-De-NoAttn.pt'\n",
    "device = torch.device(\"cuda\")\n",
    "checkpoint = torch.load(save_path)\n",
    "en = EncoderRNN(train_input_lang.n_words, hidden_size=128).to(device)\n",
    "de = DecoderRNN(hidden_size=128, output_size=train_output_lang.n_words).to(device)\n",
    "en.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "de.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "bleu = checkpoint['best_BLEU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = os.getcwd() + '/saved_model/En-CNN-De-NoAttn.pt'\n",
    "device = torch.device(\"cuda\")\n",
    "checkpoint = torch.load(save_path)\n",
    "cnn_en = EncoderCNN(hidden_size=128,kernel_dim=3,batch_size=batch_size).to(device)\n",
    "cnn_de = DecoderRNN(hidden_size=128,output_size=42228).to(device)\n",
    "cnn_en.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "cnn_de.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "bleu = checkpoint['best_BLEU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = os.getcwd() + '/saved_model/En-RNN-De-Attn-Nomask.pt'\n",
    "device = torch.device(\"cuda\")\n",
    "checkpoint = torch.load(save_path)\n",
    "encoder = EncoderRNN(hidden_size=hidden_size).to(device)\n",
    "attn_decoder = AttnDecoderRNN(hidden_size, embedding_mat_zh.shape[0]).to(device)\n",
    "encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "attn_decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "bleu = checkpoint['best_BLEU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_val(encoder, decoder, data_loader, encoder_cnn):\n",
    "    total_score = 0\n",
    "    count = 0\n",
    "    \n",
    "    candidate_corpus = []\n",
    "    reference_corpus = []\n",
    "\n",
    "    for i, (input, input_len, target, target_len) in enumerate(data_loader):\n",
    "        candidate_sentences = []\n",
    "        decoded_words = evaluate(encoder, decoder, input, input_len, encoder_cnn)\n",
    "        for ind in range(decoded_words.shape[1]):\n",
    "            sent_words = []\n",
    "            for token in decoded_words[0][ind]:\n",
    "                if token != PAD_token and token != EOS_token:\n",
    "                    sent_words.append(id2token_en[token])\n",
    "                else:\n",
    "                    break\n",
    "            sent_words = ' '.join(sent_words)\n",
    "            candidate_sentences.append(sent_words)\n",
    "#         candidate_corpus.extend(candidate_sentences)\n",
    "#             if i % 20 == 0:\n",
    "#                 input_sent = ' '.join([train_input_lang.index2word[token.item()] for token in input[ind]])\n",
    "#                 print('input: '+input_sent)\n",
    "            if i  == 2:\n",
    "                print('predict: '+sent_words)\n",
    "\n",
    "        reference_sentences = []\n",
    "        for sent in target:\n",
    "            sent_words = []\n",
    "            for token in sent:\n",
    "                if token.item() != EOS_token:\n",
    "                    sent_words.append(id2token_en[token.item()])\n",
    "                else:\n",
    "                    break\n",
    "            sent_words = ' '.join(sent_words)\n",
    "            reference_sentences.append(sent_words)\n",
    "#         reference_corpus.extend(reference_sentences)\n",
    "            if i  == 2:\n",
    "                print('target: '+sent_words)\n",
    "        \n",
    "        count += 1\n",
    "        score = corpus_bleu(candidate_sentences, [reference_sentences], smooth='exp', smooth_floor=0.0, force=False).score\n",
    "        print('batch {}: bleu: {}'.format(i+1,score))\n",
    "        total_score += score\n",
    "\n",
    "    return total_score / float(count)\n",
    "\n",
    "#     score = corpus_bleu(candidate_sentences, [reference_sentences], smooth='exp', smooth_floor=0.0, force=False).score\n",
    "#     return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1: bleu: 1.6874677926463448\n",
      "batch 2: bleu: 3.7667855569854627\n",
      "predict: and i <unk> <unk> the the <unk> <unk> the the <unk> <unk> the <unk> the the <unk> <unk> the the <unk> the of the <unk> the the <unk> the <unk> the\n",
      "predict: and i <unk> <unk> the the <unk> of the <unk> <unk> the of the\n",
      "predict: i <unk> m . . .\n",
      "predict: and i <unk> <unk> the the <unk> <unk> the the <unk> <unk> the of the\n",
      "predict: and <unk> s . . .\n",
      "predict: and i <unk> <unk> the the the <unk> the of the <unk> the of the <unk> the the the of the <unk> the of the\n",
      "predict: and <unk> <unk> the the the the the the the the of the the the the the the the the the the\n",
      "predict: and <unk> <unk> the the the the the the the the the the the the the\n",
      "predict: and <unk> <unk> the the the the the the the\n",
      "predict: and <unk> s to the the the the the the\n",
      "predict: and <unk> <unk> the the the the the the\n",
      "predict: and <unk> s the the the . .\n",
      "predict: and we <unk> the the to to to to the the the\n",
      "predict: and you <unk> <unk> the <unk> <unk> <unk> . .\n",
      "predict: and <unk> <unk> the the the the the of the <unk> the the the the the the\n",
      "predict: and <unk> <unk> the the the the the .\n",
      "predict: and <unk> <unk> the <unk> the the <unk> the the\n",
      "predict: i <unk> m to you <unk> . . .\n",
      "predict: i <unk> m to the <unk> <unk> the <unk> <unk> the <unk> the to the <unk> <unk> the to to the <unk> <unk> the <unk> <unk> the to <unk> the to to the\n",
      "predict: and <unk> s the . . .\n",
      "predict: and you <unk> re to to to the to to to to to to to the\n",
      "predict: and i <unk> <unk> the the the <unk> the the the of the\n",
      "predict: <unk> <unk> <unk> <unk> . .\n",
      "predict: and <unk> <unk> the the the the the the the the the\n",
      "predict: i i <unk> m to the <unk> <unk> .\n",
      "predict: i <unk> m to . .\n",
      "predict: and i <unk> <unk> the to the to the to .\n",
      "predict: and <unk> <unk> the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "predict: and <unk> <unk> the the the . .\n",
      "predict: and <unk> <unk> the . .\n",
      "predict: i <unk> m to the <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "predict: i <unk> <unk> <unk> <unk> the <unk> <unk> <unk> <unk>\n",
      "target: from to i look young but i <unk> m not i worked in <unk> <unk> ivory coast <unk> <unk> in projects of technical cooperation with african countries .\n",
      "target: i worked for an italian <unk> and every single project that we set up in africa failed .\n",
      "target: and i was distraught .\n",
      "target: i thought age that we <unk> were good people and we were doing good work in africa .\n",
      "target: instead everything we touched we killed .\n",
      "target: our first project the one that has inspired my first book <unk> ripples from the <unk> <unk> was a project where we <unk> decided to teach <unk> people how to grow food .\n",
      "target: so we arrived there with italian seeds in southern <unk> in this absolutely magnificent valley going down to the <unk> river and we taught the local people how to grow italian tomatoes and zucchini and . . .\n",
      "target: and of course the local people had absolutely no interest in doing that so we paid them to come and work and sometimes they would show up .\n",
      "target: and we were amazed that the local people in such a fertile valley would not have any agriculture .\n",
      "target: but instead of asking them how come they were not growing anything we simply said <unk> thank god we <unk> re here . <unk>\n",
      "target: <unk> just in the nick of time to save the <unk> people from starvation . <unk>\n",
      "target: and of course everything in africa grew beautifully .\n",
      "target: we had these magnificent tomatoes . in italy a tomato would grow to this size . in <unk> to this size .\n",
      "target: and we could not believe and we were telling the <unk> <unk> look how easy agriculture is . <unk>\n",
      "target: when the tomatoes were nice and ripe and red overnight some hippos came out from the river and they ate everything .\n",
      "target: and we said to the <unk> <unk> my god the hippos ! <unk>\n",
      "target: and the <unk> said <unk> yes that <unk> s why we have no agriculture here . <unk>\n",
      "target: <unk> why didn <unk> t you tell us ? <unk> <unk> you never asked . <unk>\n",
      "target: i thought it was only us <unk> blundering around africa but then i saw what the americans were doing what the english were doing what the french were doing and after seeing what they were doing i became quite\n",
      "target: because you see at least we fed the hippos .\n",
      "target: you should see the rubbish you should see the rubbish that we have bestowed on unsuspecting african people .\n",
      "target: you want to read the book read <unk> dead aid <unk> by <unk> <unk> <unk> woman economist .\n",
      "target: the book was published in .\n",
      "target: we western donor countries have given the african continent two trillion american dollars in the last years .\n",
      "target: i <unk> m not going to tell you the damage that that money has done .\n",
      "target: just go and read her book .\n",
      "target: read it from an african woman the damage that we have done .\n",
      "target: we western people are imperialist colonialist missionaries and there are only two ways we deal with people we either patronize them or we are paternalistic .\n",
      "target: the two words come from the latin root <unk> <unk> <unk> which means <unk> father . <unk>\n",
      "target: but they mean two different things .\n",
      "target: paternalistic i treat anybody from a different culture as if they were my children . <unk> i love you so much . <unk>\n",
      "target: patronizing i treat everybody from another culture as if they were my servants .\n",
      "batch 3: bleu: 11.163977853048632\n",
      "batch 4: bleu: 2.767766083024766\n",
      "batch 5: bleu: 4.671279622060216\n",
      "batch 6: bleu: 5.846847645561415\n",
      "batch 7: bleu: 5.7396811737175435\n",
      "batch 8: bleu: 5.773072767759805\n",
      "batch 9: bleu: 4.1470538403805985\n",
      "batch 10: bleu: 7.5928426644988205\n",
      "batch 11: bleu: 8.816536306564336\n",
      "batch 12: bleu: 7.319396389631746\n",
      "batch 13: bleu: 4.923362069870001\n",
      "batch 14: bleu: 3.1901295680337176\n",
      "batch 15: bleu: 5.502263395176081\n",
      "batch 16: bleu: 5.942242452002624\n",
      "batch 17: bleu: 8.301132427132238\n",
      "batch 18: bleu: 6.632406257430305\n",
      "batch 19: bleu: 7.845697808547803\n",
      "batch 20: bleu: 5.067028328066093\n",
      "batch 21: bleu: 4.7717474182169015\n",
      "batch 22: bleu: 2.45778784538963\n",
      "batch 23: bleu: 6.962748747051737\n",
      "batch 24: bleu: 3.9682526909493587\n",
      "batch 25: bleu: 3.6992286281967335\n",
      "batch 26: bleu: 4.788200646509859\n",
      "batch 27: bleu: 2.3486931892166694\n",
      "batch 28: bleu: 2.1813160041727864\n",
      "batch 29: bleu: 7.034604607387435\n",
      "batch 30: bleu: 3.545119137412489\n",
      "batch 31: bleu: 5.257597076393892\n",
      "batch 32: bleu: 4.651669609396927\n",
      "batch 33: bleu: 7.269835605806074\n",
      "batch 34: bleu: 5.457282123213394\n",
      "batch 35: bleu: 3.59470851109465\n",
      "batch 36: bleu: 3.6383812491598526\n",
      "batch 37: bleu: 3.16165043603489\n",
      "batch 38: bleu: 6.28703636306102\n",
      "batch 39: bleu: 7.796214044000326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.271001126533414"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_val(encoder,attn_decoder,val_loader,encoder_cnn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: m submarines bizarre lange big earth captured captured captured\n",
      "predict: the submarines bizarre the the the the the the captured\n",
      "predict: us the the the the the the the\n",
      "predict: us submarines bizarre the the the captured captured\n",
      "predict: the submarines bizarre the the the the the the captured captured\n",
      "predict: the submarines bizarre the the the volcanic captured captured\n",
      "predict: m submarines bizarre big the captured captured captured\n",
      "predict: get m submarines bizarre captured\n",
      "predict: the submarines bizarre the the the the the captured captured\n",
      "predict: the submarines bizarre the the the the the the the the captured\n",
      "predict: to submarines some lange the earth the volcanic captured captured captured\n",
      "predict: to submarines some of earth earth earth the volcanic captured captured\n",
      "predict: to submarines habitats valleys earth earth earth the volcanic the captured captured captured\n",
      "predict: get to submarines some animal the volcanic earth the to captured captured\n",
      "predict: hardwired s submarines some of earth\n",
      "predict: to submarines some of earth earth the the volcanic the captured captured\n",
      "predict: landscapes submarines some the the the volcanic the captured captured\n",
      "predict: to submarines some of earth earth captured captured captured\n",
      "predict: to submarines some to captured captured captured captured\n",
      "predict: become to submarines some of earth captured captured\n",
      "predict: to submarines some of earth earth earth captured captured captured captured\n",
      "predict: us produces trials trials trials trials produces trials produces captured captured captured\n",
      "predict: the submarines bizarre the the the the captured captured\n",
      "predict: the submarines volcanic the the the the the the the the the\n",
      "predict: us submarines bizarre the the volcanic captured captured\n",
      "predict: us submarines bizarre\n",
      "predict: produces produces trials trials trials produces trials produces trials captured captured captured\n",
      "predict: the submarines bizarre the the the the the the the captured captured\n",
      "predict: the submarines bizarre the the the the the captured captured\n",
      "predict: the submarines bizarre the the the the captured captured captured\n",
      "predict: the submarines bizarre the the the the the captured captured captured\n",
      "predict: us the submarines s volcanic the the the the the volcanic\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "target: my father was listening to bbc news on his small gray radio .\n",
      "target: there was a big smile on his face which was unusual then because the news mostly depressed him .\n",
      "target: quot the taliban are gone ! quot my father shouted .\n",
      "target: i didn apos t know what it meant but i could see that my father was very very happy .\n",
      "target: quot you can go to a real school now quot he said .\n",
      "target: a morning that i will never forget .\n",
      "target: a real school .\n",
      "target: you see i was six when the taliban took over afghanistan and made it illegal for girls to go to school .\n",
      "target: so for the next five years i dressed as a boy to escort my older sister who was no longer allowed to be outside alone to a secret school .\n",
      "target: it was the only way we both could be educated .\n",
      "target: each day we took a different route so that no one would suspect where we were going .\n",
      "target: we would cover our books in grocery bags so it would seem we were just out shopping .\n",
      "target: the school was in a house more than of us packed in one small living room .\n",
      "target: it was cozy in winter but extremely hot in summer .\n",
      "target: we all knew we were risking our lives the teacher the students and our parents .\n",
      "target: from time to time the school would suddenly be canceled for a week because taliban were suspicious .\n",
      "target: we always wondered what they knew about us .\n",
      "target: were we being followed ?\n",
      "target: do they know where we live ?\n",
      "target: we were scared but still school was where we wanted to be .\n",
      "target: i was very lucky to grow up in a family where education was prized and daughters were treasured .\n",
      "target: my grandfather was an extraordinary man for his time .\n",
      "target: a total maverick from a remote province of afghanistan he insisted that his daughter my mom go to school and for that he was <unk> by his father .\n",
      "target: but my educated mother became a teacher .\n",
      "target: there she is .\n",
      "target: she retired two years ago only to turn our house into a school for girls and women in our neighborhood .\n",
      "target: and my father that apos s him he was the first ever in his family to receive an education .\n",
      "target: there was no question that his children would receive an education including his daughters despite the taliban despite the risks .\n",
      "target: to him there was greater risk in not educating his children .\n",
      "target: during taliban years i remember there were times i would get so frustrated by our life and always being scared and not seeing a future .\n",
      "target: i would want to quit but my father he would say quot listen my daughter you can lose everything you own in your life .\n",
      "batch 1: bleu: 0.14123117618136216\n",
      "batch 2: bleu: 0.10371848937899429\n",
      "batch 3: bleu: 0.12294021959087092\n",
      "batch 4: bleu: 0.12307199775175377\n",
      "batch 5: bleu: 0.14256899296711822\n",
      "batch 6: bleu: 0.1374606154918132\n",
      "batch 7: bleu: 0.11426978903756657\n",
      "batch 8: bleu: 0.13308689955589886\n",
      "batch 9: bleu: 0.0892428906635375\n",
      "batch 10: bleu: 0.11007645978455693\n",
      "batch 11: bleu: 0.08730251994300726\n",
      "batch 12: bleu: 0.08137329110548429\n",
      "batch 13: bleu: 0.09868555239880164\n",
      "batch 14: bleu: 0.09224425743593917\n",
      "batch 15: bleu: 0.18717445268505148\n",
      "batch 16: bleu: 0.14233620623123658\n",
      "batch 17: bleu: 0.12116015670807967\n",
      "batch 18: bleu: 0.138822624738952\n",
      "batch 19: bleu: 0.13365710422893826\n",
      "batch 20: bleu: 0.1444530333895006\n",
      "predict: the submarines bizarre the the the the the the the the captured captured\n",
      "predict: produces submarines trials trials trials considerable waters us produces submarines bizarre captured captured captured captured\n",
      "predict: us submarines bizarre the the volcanic the captured captured\n",
      "predict: produces produces produces produces trials produces produces produces produces trials produces produces\n",
      "predict: produces produces trials trials produces trials produces trials trials captured captured\n",
      "predict: the submarines bizarre the the the captured captured\n",
      "predict: to submarines some of earth earth the captured captured captured\n",
      "predict: to submarines some of earth the in the the the captured captured\n",
      "predict: to submarines some animal earth earth gets gets gets captured captured captured\n",
      "predict: to submarines some of earth earth earth earth to to earth captured captured\n",
      "predict: the submarines bizarre the the the the the the the the captured\n",
      "predict: produces produces trials produces produces trials produces produces trials captured\n",
      "predict: us submarines bizarre the the the captured captured\n",
      "predict: by submarines david of earth earth earth by by captured captured\n",
      "predict: the submarines bizarre the the the the the captured captured captured\n",
      "predict: us the bizarre bizarre volcanic the earth the by by the captured\n",
      "predict: produces produces produces produces trials produces produces produces produces captured captured\n",
      "predict: us submarines bizarre the the the the captured\n",
      "predict: us submarines bizarre the the the volcanic captured captured\n",
      "predict: by submarines david of earth earth the volcanic the captured captured\n",
      "predict: with vibrant big blue volcanic the the the the\n",
      "predict: us the submarines bizarre the volcanic in the the the the the the the the the the the\n",
      "predict: to submarines some big big the volcanic earth the earth the earth the earth the earth the\n",
      "predict: us to submarines some of earth captured captured captured\n",
      "predict: us submarines bizarre the earth captured captured captured\n",
      "predict: produces produces bizarre trials produces trials produces trials earth captured captured\n",
      "predict: the submarines the the the the the the the captured captured\n",
      "predict: the submarines volcanic to the volcanic hiding volcanic the earth earth the hiding volcanic earth the earth the earth the\n",
      "predict: the submarines bizarre the the the the the earth captured captured captured\n",
      "predict: produces produces trials trials trials trials trials trials trials trials trials trials captured captured captured captured\n",
      "predict: to submarines habitats valleys big pills allow in the shimmering captured\n",
      "predict: the submarines volcanic by by submarines volcanic by by the earth the earth the by the earth\n",
      "target: soon after an organization i volunteer with all hands volunteers were on the ground within days working as part of the response efforts .\n",
      "target: i along with hundreds of other volunteers knew we couldn apos t just sit at home so i decided to join them for three weeks .\n",
      "target: on may the th i made my way to the town of <unk> .\n",
      "target: it apos s a small fishing town in <unk> prefecture about people one of the first that was hit by the wave .\n",
      "target: the waters here have been recorded at reaching over meters in height and traveled over two miles inland .\n",
      "target: as you can imagine the town had been devastated .\n",
      "target: we pulled debris from canals and ditches .\n",
      "target: we cleaned schools . we de <unk> and gutted homes ready for renovation and rehabilitation .\n",
      "target: we cleared tons and tons of stinking rotting fish carcasses from the local fish processing plant .\n",
      "target: we got dirty and we loved it .\n",
      "target: for weeks all the volunteers and locals alike had been finding similar things .\n",
      "target: they apos d been finding photos and photo albums and cameras and sd cards .\n",
      "target: and everyone was doing the same .\n",
      "target: they were collecting them up and handing them in to various places around the different towns for <unk> .\n",
      "target: now it wasn apos t until this point that i realized that these photos were such a huge part of the personal loss these people had felt .\n",
      "target: as they had run from the wave and for their lives absolutely everything they had everything had to be left behind .\n",
      "target: at the end of my first week there i found myself helping out in an evacuation center in the town .\n",
      "target: i was helping clean the <unk> the communal <unk> the huge giant <unk> .\n",
      "target: this happened to also be a place in the town where the evacuation center was collecting the photos .\n",
      "target: this is where people were handing them in and i was honored that day that they actually trusted me to help them start hand cleaning them .\n",
      "target: now it was emotional and it was inspiring and i apos ve always heard about thinking outside the box but it wasn apos t until i had actually gotten outside of my box that something happened .\n",
      "target: as i looked through the photos there were some were over a hundred years old some still in the envelope from the processing lab i couldn apos t help but think as a <unk> that i could fix that tear\n",
      "target: so that evening i just reached out on facebook and asked a few of them and by morning the response had been so overwhelming and so positive i knew we had to give it a go .\n",
      "target: so we started <unk> photos .\n",
      "target: this was the very first .\n",
      "target: not terribly damaged but where the water had caused that <unk> on the girl apos s face had to be repaired with such accuracy and delicacy .\n",
      "target: otherwise that little girl isn apos t going to look like that little girl anymore and surely that apos s as tragic as having the photo damaged .\n",
      "target: over time more photos came in thankfully and more retouchers were needed and so i reached out again on facebook and linkedin and within five days people wanted to help from different countries .\n",
      "target: within two weeks i had people wanting to join in .\n",
      "target: within japan by july we apos d branched out to the neighboring town of <unk> further north to a town called <unk> .\n",
      "target: once a week we would set up our scanning equipment in the temporary photo libraries that had been set up where people were reclaiming their photos .\n",
      "target: the older ladies sometimes hadn apos t seen a scanner before but within minutes of them finding their lost photo they could give it to us have it scanned uploaded to a cloud server it would be downloaded by a\n",
      "batch 21: bleu: 0.21815323297305297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 22: bleu: 0.12591854302765146\n",
      "batch 23: bleu: 0.10199104658234201\n",
      "batch 24: bleu: 0.08889222036908966\n",
      "batch 25: bleu: 0.10508610322666333\n",
      "batch 26: bleu: 0.12327139014581195\n",
      "batch 27: bleu: 0.1129226399275569\n",
      "batch 28: bleu: 0.11091220140580191\n",
      "batch 29: bleu: 0.11342733507495625\n",
      "batch 30: bleu: 0.1200610555414891\n",
      "batch 31: bleu: 0.12259024916341915\n",
      "batch 32: bleu: 0.17780114766473706\n",
      "batch 33: bleu: 0.10454691228489726\n",
      "batch 34: bleu: 0.08041177840733403\n",
      "batch 35: bleu: 0.10092450598329217\n",
      "batch 36: bleu: 0.11306688865727357\n",
      "batch 37: bleu: 0.08009273840678621\n",
      "batch 38: bleu: 0.11597295158093461\n",
      "batch 39: bleu: 0.09587407112735168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1194049677133052"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_val(cnn_en,cnn_de,val_loader,encoder_cnn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "target: my father was listening to bbc news on his small gray radio .\n",
      "target: there was a big smile on his face which was unusual then because the news mostly depressed him .\n",
      "target: quot the taliban are gone ! quot my father shouted .\n",
      "target: i didn apos t know what it meant but i could see that my father was very very happy .\n",
      "target: quot you can go to a real school now quot he said .\n",
      "target: a morning that i will never forget .\n",
      "target: a real school .\n",
      "target: you see i was six when the taliban took over afghanistan and made it illegal for girls to go to school .\n",
      "target: so for the next five years i dressed as a boy to escort my older sister who was no longer allowed to be outside alone to a secret school .\n",
      "target: it was the only way we both could be educated .\n",
      "target: each day we took a different route so that no one would suspect where we were going .\n",
      "target: we would cover our books in grocery bags so it would seem we were just out shopping .\n",
      "target: the school was in a house more than of us packed in one small living room .\n",
      "target: it was cozy in winter but extremely hot in summer .\n",
      "target: we all knew we were risking our lives the teacher the students and our parents .\n",
      "target: from time to time the school would suddenly be canceled for a week because taliban were suspicious .\n",
      "target: we always wondered what they knew about us .\n",
      "target: were we being followed ?\n",
      "target: do they know where we live ?\n",
      "target: we were scared but still school was where we wanted to be .\n",
      "target: i was very lucky to grow up in a family where education was prized and daughters were treasured .\n",
      "target: my grandfather was an extraordinary man for his time .\n",
      "target: a total maverick from a remote province of afghanistan he insisted that his daughter my mom go to school and for that he was <unk> by his father .\n",
      "target: but my educated mother became a teacher .\n",
      "target: there she is .\n",
      "target: she retired two years ago only to turn our house into a school for girls and women in our neighborhood .\n",
      "target: and my father that apos s him he was the first ever in his family to receive an education .\n",
      "target: there was no question that his children would receive an education including his daughters despite the taliban despite the risks .\n",
      "target: to him there was greater risk in not educating his children .\n",
      "target: during taliban years i remember there were times i would get so frustrated by our life and always being scared and not seeing a future .\n",
      "target: i would want to quit but my father he would say quot listen my daughter you can lose everything you own in your life .\n",
      "batch 1: bleu: 0.49096048123730085\n",
      "batch 2: bleu: 0.3939004020449434\n",
      "batch 3: bleu: 0.8617070713886422\n",
      "batch 4: bleu: 0.5041387990265633\n",
      "batch 5: bleu: 1.156053426610965\n",
      "batch 6: bleu: 0.9132737718555536\n",
      "batch 7: bleu: 0.6303381844163454\n",
      "batch 8: bleu: 0.5636224973993404\n",
      "batch 9: bleu: 1.079071789614086\n",
      "batch 10: bleu: 2.476928242868487\n",
      "batch 11: bleu: 0.9545183348898235\n",
      "batch 12: bleu: 1.261693182786175\n",
      "batch 13: bleu: 0.7326649054486112\n",
      "batch 14: bleu: 0.5948577203122039\n",
      "batch 15: bleu: 0.6777762127028494\n",
      "batch 16: bleu: 0.9456560627023767\n",
      "batch 17: bleu: 1.9658038142674101\n",
      "batch 18: bleu: 1.7121587607418256\n",
      "batch 19: bleu: 2.7173620584948073\n",
      "batch 20: bleu: 1.153589126496657\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "target: soon after an organization i volunteer with all hands volunteers were on the ground within days working as part of the response efforts .\n",
      "target: i along with hundreds of other volunteers knew we couldn apos t just sit at home so i decided to join them for three weeks .\n",
      "target: on may the th i made my way to the town of <unk> .\n",
      "target: it apos s a small fishing town in <unk> prefecture about people one of the first that was hit by the wave .\n",
      "target: the waters here have been recorded at reaching over meters in height and traveled over two miles inland .\n",
      "target: as you can imagine the town had been devastated .\n",
      "target: we pulled debris from canals and ditches .\n",
      "target: we cleaned schools . we de <unk> and gutted homes ready for renovation and rehabilitation .\n",
      "target: we cleared tons and tons of stinking rotting fish carcasses from the local fish processing plant .\n",
      "target: we got dirty and we loved it .\n",
      "target: for weeks all the volunteers and locals alike had been finding similar things .\n",
      "target: they apos d been finding photos and photo albums and cameras and sd cards .\n",
      "target: and everyone was doing the same .\n",
      "target: they were collecting them up and handing them in to various places around the different towns for <unk> .\n",
      "target: now it wasn apos t until this point that i realized that these photos were such a huge part of the personal loss these people had felt .\n",
      "target: as they had run from the wave and for their lives absolutely everything they had everything had to be left behind .\n",
      "target: at the end of my first week there i found myself helping out in an evacuation center in the town .\n",
      "target: i was helping clean the <unk> the communal <unk> the huge giant <unk> .\n",
      "target: this happened to also be a place in the town where the evacuation center was collecting the photos .\n",
      "target: this is where people were handing them in and i was honored that day that they actually trusted me to help them start hand cleaning them .\n",
      "target: now it was emotional and it was inspiring and i apos ve always heard about thinking outside the box but it wasn apos t until i had actually gotten outside of my box that something happened .\n",
      "target: as i looked through the photos there were some were over a hundred years old some still in the envelope from the processing lab i couldn apos t help but think as a <unk> that i could fix that tear\n",
      "target: so that evening i just reached out on facebook and asked a few of them and by morning the response had been so overwhelming and so positive i knew we had to give it a go .\n",
      "target: so we started <unk> photos .\n",
      "target: this was the very first .\n",
      "target: not terribly damaged but where the water had caused that <unk> on the girl apos s face had to be repaired with such accuracy and delicacy .\n",
      "target: otherwise that little girl isn apos t going to look like that little girl anymore and surely that apos s as tragic as having the photo damaged .\n",
      "target: over time more photos came in thankfully and more retouchers were needed and so i reached out again on facebook and linkedin and within five days people wanted to help from different countries .\n",
      "target: within two weeks i had people wanting to join in .\n",
      "target: within japan by july we apos d branched out to the neighboring town of <unk> further north to a town called <unk> .\n",
      "target: once a week we would set up our scanning equipment in the temporary photo libraries that had been set up where people were reclaiming their photos .\n",
      "target: the older ladies sometimes hadn apos t seen a scanner before but within minutes of them finding their lost photo they could give it to us have it scanned uploaded to a cloud server it would be downloaded by a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 21: bleu: 0.7090420408048385\n",
      "batch 22: bleu: 0.47676412889722\n",
      "batch 23: bleu: 2.0270913893564497\n",
      "batch 24: bleu: 0.371090549424509\n",
      "batch 25: bleu: 1.067189592769331\n",
      "batch 26: bleu: 1.1906195417586753\n",
      "batch 27: bleu: 0.7621629074750933\n",
      "batch 28: bleu: 1.0430932182527446\n",
      "batch 29: bleu: 1.3534049587438952\n",
      "batch 30: bleu: 1.1687269055231078\n",
      "batch 31: bleu: 1.0057984051085882\n",
      "batch 32: bleu: 0.9683688958798589\n",
      "batch 33: bleu: 1.045485361533528\n",
      "batch 34: bleu: 0.41718143946528957\n",
      "batch 35: bleu: 0.4990749788577744\n",
      "batch 36: bleu: 0.7737583152500009\n",
      "batch 37: bleu: 0.5667263889375768\n",
      "batch 38: bleu: 0.4541978565349855\n",
      "batch 39: bleu: 0.936236091090201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9903099438709904"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_val(en,de,val_loader,encoder_cnn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
