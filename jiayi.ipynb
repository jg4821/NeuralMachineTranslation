{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import io\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "import itertools\n",
    "import glob\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "from sacrebleu import corpus_bleu\n",
    "import sacrebleu\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "words_to_load = 100000\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_token = 2\n",
    "UNK_token = 3\n",
    "LR_RATE = 0.001\n",
    "MAX_LENGTH = 100\n",
    "hidden_size = 128\n",
    "teacher_forcing_ratio = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Preprocess Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"<pad>\", 3: \"<unk>\"}\n",
    "        self.n_words = 4  # Count SOS, EOS, pad and unk\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(dataset, lang1, lang2):\n",
    "    chinese = os.getcwd()+'/iwslt-zh-en/{}.tok.{}'.format(dataset, lang1)\n",
    "    english = os.getcwd()+'/iwslt-zh-en/{}.tok.{}'.format(dataset, lang2)\n",
    "\n",
    "    chinese_lines = open(chinese, encoding='utf-8').read().strip().split('\\n')\n",
    "    english_lines = open(english, encoding='utf-8').read().strip().split('\\n')\n",
    "    length = len(chinese_lines)\n",
    "\n",
    "    pairs = [[chinese_lines[i], normalizeString(english_lines[i])] for i in range(length)]\n",
    "    pairs = filterPairs(pairs)\n",
    "    \n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_lang, train_output_lang, train_pairs = readLangs('train', 'zh', 'en')\n",
    "val_input_lang, val_output_lang, val_pairs = readLangs('dev', 'zh', 'en')\n",
    "test_input_lang, test_output_lang, test_pairs = readLangs('test', 'zh', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你们'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_lang.index2word[399]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['深海 海中 的 生命   大卫   盖罗 ', 'life in the deep oceans']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Loader__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_lang, output_lang, pairs):\n",
    "        \"\"\"\n",
    "        @param data_list_1: list of sentence 1 tokens \n",
    "        @param data_list_2: list of sentence 2 tokens\n",
    "        @param target_list: list of review targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.input_lang = input_lang\n",
    "        self.output_lang = output_lang\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        input_sentence = self.pairs[key][0]\n",
    "        input_indexes = [self.input_lang.word2index[word] for word in input_sentence.split(' ')]\n",
    "        input_indexes.append(EOS_token)\n",
    "        input_length = len(input_indexes)\n",
    "\n",
    "        output_sentence = self.pairs[key][1]\n",
    "        output_indexes = [self.output_lang.word2index[word] for word in output_sentence.split(' ')]\n",
    "        output_indexes.append(EOS_token)\n",
    "        output_length = len(output_indexes)\n",
    "        return [input_indexes, input_length, output_indexes, output_length]\n",
    "\n",
    "    \n",
    "def NMTDataset_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    input_ls = []\n",
    "    output_ls = []\n",
    "    input_length_ls = []\n",
    "    output_length_ls = []\n",
    "    \n",
    "    for datum in batch:\n",
    "        input_length_ls.append(datum[1])\n",
    "        output_length_ls.append(datum[3])\n",
    "    \n",
    "    #find max length in each batch\n",
    "    max_input = sorted(input_length_ls)[-1]\n",
    "    max_output = sorted(output_length_ls)[-1]\n",
    "    \n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec_input = np.pad(np.array(datum[0]), \n",
    "                                  pad_width=((0,max_input-datum[1])), \n",
    "                                  mode=\"constant\", constant_values=2).tolist()\n",
    "        padded_vec_output = np.pad(np.array(datum[2]), \n",
    "                                   pad_width=((0,max_output-datum[3])), \n",
    "                                   mode=\"constant\", constant_values=2).tolist()\n",
    "        input_ls.append(padded_vec_input)\n",
    "        output_ls.append(padded_vec_output)\n",
    "    return [torch.tensor(torch.from_numpy(np.array(input_ls)), device=device), \n",
    "            torch.tensor(input_length_ls, device=device), \n",
    "            torch.tensor(torch.from_numpy(np.array(output_ls)), device=device), \n",
    "            torch.tensor(output_length_ls, device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pytorch dataloader\n",
    "train_dataset = NMTDataset(train_input_lang, train_output_lang, train_pairs)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size,\n",
    "                                           collate_fn=NMTDataset_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = NMTDataset(val_input_lang, val_output_lang, val_pairs)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         collate_fn=NMTDataset_collate_func,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are stars . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "i really hope you can see how what we apos re doing here is taking a compelling question a compelling answer but we apos re paving a smooth straight path from one to the other and congratulating our students for how well they can step over the small cracks in the way . EOS\n",
      "he did after all have a toy gun . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "this is a part of that . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "but let apos s suppose some aliens had been watching our pale blue dot in the cosmos from afar not just for years but for the entire . billion year history of our earth . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "so i said quot no no really it apos s penguin shit . quot  EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "they work through interaction they create a capability and then it uses that capability to bring on the next stage . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "you can see from the slide very very strong . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tzvika we have no information . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      " quot i do . quot  EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "now i grew up in the apos s and i apos ll admit it actually my childhood spanned the apos s and i was a wannabe hippie and i always resented the fact that i wasn apos t really old enough to be a hippie . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "so with that let me just show you a quick video to get you in the mood of what we apos re trying to explain . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "but if you now take a set of replicating guys like in the video that you saw it looks like this . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "thank you very much . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "here in north america we have more than different kinds of firefly that have the remarkable ability to shine energy out from their bodies in the form of light . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "the pilot is good . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "heck they can even mute the professor . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "in addition to making this personal so we apos re going to talk about your relationship with your heart and all women apos s relationship with their heart we apos re going to wax into the politics . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "so these are the things that you don apos t find elsewhere but you do find at the office . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "horrible chest pain . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "in this case also because it apos s part of one of the many sentiments that we build the whole series on that all the sentiments originally had come out of the diary . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "and you can win when you apos re outscored . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "now that sounds absurd in singapore to say that because here shipping is so present that you stuck a ship on top of a hotel . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "two by four construction is sort of like the little eight dot bricks of lego that we all played with as kids and you can make all kinds of cool things out of lego at that size and out of two by fours . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "but this one apos s kind of cool . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "rb well the nice thing about ted is everybody apos s interesting . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "i can use it in my company . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "thank you . thank you . thank you . thank you . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "donate it take it and so on . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "my geiger counter dosimeter which measures radiation was going berserk and the closer i got the more frenetic it became and frantic . my god . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "now we don apos t get to . percent . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "you can it turns out be in two places at once . EOS <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "#     print(i)\n",
    "#     print(i[2])\n",
    "#     for ind in i[2]:\n",
    "#         for token in ind:\n",
    "#             print(token)\n",
    "#             print(train_output_lang.index2word[token.item()])\n",
    "    for ind in i[2]:\n",
    "        print(' '.join(train_output_lang.index2word[token.item()] for token in ind))\n",
    "#     print([train_output_lang.index2word[token.item()] for ind in i[2] for token in ind])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Embedding__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding(ft_path, words_to_load):\n",
    "    fin = io.open(ft_path, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    vocab_size = words_to_load + 4\n",
    "    embedding_dim = d\n",
    "\n",
    "    embedding_mat = np.zeros((vocab_size, embedding_dim))\n",
    "    token2id = {}\n",
    "    id2token = {}\n",
    "    all_tokens = ['SOS', 'EOS', '<unk>', '<pad>']\n",
    "\n",
    "    for i, line in enumerate(fin):\n",
    "        if i >= words_to_load:\n",
    "            break\n",
    "        s = line.rstrip().split(' ')\n",
    "        embedding_mat[i+4, :] = np.asarray(s[1:])\n",
    "        token2id[s[0]] = i+4\n",
    "        id2token[i+4] = s[0]\n",
    "        all_tokens.append(s[0])\n",
    "\n",
    "        token2id['<pad>'] = PAD_token \n",
    "        token2id['<unk>'] = UNK_token\n",
    "        token2id['SOS'] = SOS_token\n",
    "        token2id['EOS'] = EOS_token\n",
    "        id2token[PAD_token] = '<pad>'\n",
    "        id2token[UNK_token] = '<unk>'\n",
    "        id2token[SOS_token] = 'SOS'\n",
    "        id2token[EOS_token] = 'EOS'\n",
    "        embedding_mat[PAD_token, :] = np.zeros((1,d))\n",
    "        #generate normal dist 1d array for UNK, SOS, EOS token\n",
    "        embedding_mat[UNK_token, :] = np.random.normal(size=d)\n",
    "        embedding_mat[SOS_token, :] = np.random.normal(size=d)\n",
    "        embedding_mat[EOS_token, :] = np.random.normal(size=d)\n",
    "        \n",
    "    return embedding_mat, all_tokens, token2id, id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_zh = os.getcwd()+'/wiki.zh.vec'\n",
    "fname_eng = '/'.join(os.getcwd().split('/')[:-1])+'/hw2/wiki-news-300d-1M.vec'\n",
    "embedding_mat_zh, all_tokens_zh, token2id_zh, id2token_zh = load_embedding(fname_zh, words_to_load)\n",
    "embedding_mat_en, all_tokens_en, token2id_en, id2token_en = load_embedding(fname_eng, words_to_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Encoder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        embed_mat = torch.from_numpy(embedding_mat_zh).float()\n",
    "        n, embed_dim = embed_mat.shape\n",
    "        mask = np.zeros((n,1))\n",
    "        mask[0] = 1\n",
    "        mask[1] = 1\n",
    "        mask[2] = 1\n",
    "        mask[3] = 1\n",
    "        mask = torch.from_numpy(mask).float()\n",
    "        self.mask_embedding = nn.Embedding.from_pretrained(mask, freeze = False)\n",
    "        self.embedding = nn.Embedding.from_pretrained(embed_mat, freeze = True)\n",
    "        \n",
    "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input, input_len, hidden):\n",
    "        # Compute sorted sequence lengths\n",
    "        _, idx_sort = torch.sort(input_len, dim=0, descending=True)\n",
    "        _, idx_unsort = torch.sort(idx_sort, dim=0)\n",
    "        \n",
    "        # get embedding of characters\n",
    "        embed = self.embedding(input)\n",
    "        mask = self.mask_embedding(input)\n",
    "        \n",
    "        embedded = mask*embed + (1-mask)*embed.clone().detach()\n",
    "        \n",
    "        # Sort embedding and length\n",
    "        embedded = embedded.index_select(0, idx_sort)\n",
    "        input_len = input_len.index_select(0, idx_sort)\n",
    "        \n",
    "        packed_emb = nn.utils.rnn.pack_padded_sequence(embedded, input_len.cpu().numpy(), batch_first=True)\n",
    "        packed_output, hidden = self.gru(packed_emb, hidden)\n",
    "        output, output_lens =  nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        # Unsort output and last hidden unit\n",
    "        output = output.index_select(0, idx_unsort)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Decoder Without Attention__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        embed_mat = torch.from_numpy(embedding_mat_en).float()\n",
    "        n, embed_dim = embed_mat.shape\n",
    "        mask = np.zeros((n,1))\n",
    "        mask[0] = 1\n",
    "        mask[1] = 1\n",
    "        mask[2] = 1\n",
    "        mask[3] = 1\n",
    "        mask = torch.from_numpy(mask).float()\n",
    "        self.mask_embedding = nn.Embedding.from_pretrained(mask, freeze = False)\n",
    "        self.embedding = nn.Embedding.from_pretrained(embed_mat, freeze = True)\n",
    "        \n",
    "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, word_input, hidden):\n",
    "        # get embedding of words\n",
    "        embed = self.embedding(word_input)\n",
    "        mask = self.mask_embedding(word_input)\n",
    "        \n",
    "        embedded = mask*embed + (1-mask)*embed.clone().detach()\n",
    "\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        \n",
    "        # Final output layer\n",
    "        output = output.squeeze(1) # B x N\n",
    "        output = self.linear(output)\n",
    "        output = self.softmax(output)\n",
    "\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input, target, input_len, target_len, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH, teach_forcing_ratio=0.5):\n",
    "    encoder_hidden = encoder.initHidden(batch_size)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    max_input_len = max(input_len)\n",
    "    max_target_len = max(target_len)\n",
    "\n",
    "    encoder_outputs = torch.zeros([batch_size, max_input_len, encoder.hidden_size], device=device)\n",
    "    loss = 0\n",
    "\n",
    "    encoder_output, encoder_hidden = encoder(input, input_len, encoder_hidden)\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]]*batch_size, device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target[:,di])\n",
    "            decoder_input = target[:,di].unsqueeze(1)  # Teacher forcing (batch_size, 1)\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach().unsqueeze(1)  # detach from history as input\n",
    "            loss += criterion(decoder_output, target[:,di])\n",
    "    #         if decoder_input.item() == EOS_token:\n",
    "    #             break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / float(max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(loader, encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        for i, (input, input_len, target, target_len) in enumerate(loader):\n",
    "            loss = train(input, target, input_len, target_len, encoder, decoder, \n",
    "                         encoder_optimizer, decoder_optimizer, criterion, \n",
    "                         max_length=MAX_LENGTH, teach_forcing_ratio=teacher_forcing_ratio)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "            \n",
    "            # TO DO: ADD BLEU\n",
    "            if i % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / float(print_every)\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                             iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "            if i % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "#     showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 0s (- 0m 0s) (1 100%) 10.0000\n",
      "0m 0s (- 0m 0s) (1 100%) 10.0000\n",
      "0m 0s (- 0m 0s) (1 100%) 10.0000\n",
      "0m 0s (- 0m 0s) (1 100%) 10.0000\n",
      "0m 0s (- 0m 0s) (1 100%) 10.0000\n",
      "0m 1s (- 0m 0s) (1 100%) 10.0000\n",
      "0m 1s (- 0m 0s) (1 100%) 10.0000\n",
      "0m 1s (- 0m 0s) (1 100%) 10.0000\n",
      "0m 1s (- 0m 0s) (1 100%) 10.0000\n",
      "0m 1s (- 0m 0s) (1 100%) 10.0000\n",
      "0m 1s (- 0m 0s) (1 100%) 10.0000\n",
      "0m 1s (- 0m 0s) (1 100%) 10.0000\n",
      "0m 2s (- 0m 0s) (1 100%) 10.0000\n",
      "0m 2s (- 0m 0s) (1 100%) 10.0000\n",
      "0m 2s (- 0m 0s) (1 100%) 10.0000\n",
      "0m 2s (- 0m 0s) (1 100%) 9.0000\n",
      "0m 2s (- 0m 0s) (1 100%) 9.0000\n",
      "0m 2s (- 0m 0s) (1 100%) 8.0000\n",
      "0m 3s (- 0m 0s) (1 100%) 8.0000\n",
      "0m 3s (- 0m 0s) (1 100%) 7.0000\n",
      "0m 3s (- 0m 0s) (1 100%) 6.0000\n",
      "0m 3s (- 0m 0s) (1 100%) 6.0000\n",
      "0m 3s (- 0m 0s) (1 100%) 6.0000\n",
      "0m 3s (- 0m 0s) (1 100%) 6.0000\n",
      "0m 4s (- 0m 0s) (1 100%) 5.0000\n",
      "0m 4s (- 0m 0s) (1 100%) 5.0000\n",
      "0m 4s (- 0m 0s) (1 100%) 5.0000\n",
      "0m 4s (- 0m 0s) (1 100%) 4.0000\n",
      "0m 4s (- 0m 0s) (1 100%) 4.0000\n",
      "0m 4s (- 0m 0s) (1 100%) 5.0000\n",
      "0m 4s (- 0m 0s) (1 100%) 4.0000\n",
      "0m 5s (- 0m 0s) (1 100%) 3.0000\n",
      "0m 5s (- 0m 0s) (1 100%) 3.0000\n",
      "0m 5s (- 0m 0s) (1 100%) 3.0000\n",
      "0m 5s (- 0m 0s) (1 100%) 3.0000\n",
      "0m 5s (- 0m 0s) (1 100%) 2.0000\n",
      "0m 5s (- 0m 0s) (1 100%) 3.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-801884445cb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#UNCOMMENT TO TRAIN THE MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoattn_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-d8e03f9dd8f0>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(loader, encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     14\u001b[0m             loss = train(input, target, input_len, target_len, encoder, decoder, \n\u001b[1;32m     15\u001b[0m                          \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                          max_length=MAX_LENGTH, teach_forcing_ratio=teacher_forcing_ratio)\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-73a842cf95cc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input, target, input_len, target_len, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length, teach_forcing_ratio)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSOS_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-4ac7b8428c35>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, input_len, hidden)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mpacked_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mpacked_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lens\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Unsort output and last hidden unit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.6/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# fast pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmight_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mflat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_tensors_permissive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.6/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpad_packed_sequence\u001b[0;34m(sequence, batch_first, padding_value, total_length)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev_batch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprev_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_offset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdata_offset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mprev_batch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprev_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0mdata_offset\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mprev_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(train_input_lang.n_words, hidden_size).to(device)\n",
    "noattn_decoder = DecoderRNN(hidden_size, train_output_lang.n_words).to(device)\n",
    "# attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "# attn_decoder1 = BahdanauAttnDecoderRNN(hidden_size, output_lang.n_words, n_layers=1, dropout_p=0.1).to(device)\n",
    "\n",
    "#UNCOMMENT TO TRAIN THE MODEL\n",
    "trainIters(train_loader, encoder, noattn_decoder, n_iters=1, print_every=1, plot_every=1, learning_rate=LR_RATE)\n",
    "# trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\n",
    "\n",
    "# encoder.load_state_dict(torch.load(\"encoder.pth\"))\n",
    "# attn_decoder1.load_state_dict(torch.load(\"attn_decoder.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, input, input_len, max_length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    Function that generate translation.\n",
    "    First, feed the source sentence into the encoder and obtain the hidden states from encoder.\n",
    "    Secondly, feed the hidden states into the decoder and unfold the outputs from the decoder.\n",
    "    Lastly, for each outputs from the decoder, collect the corresponding words in the target language's vocabulary.\n",
    "    And collect the attention for each output words.\n",
    "    @param encoder: the encoder network\n",
    "    @param decoder: the decoder network\n",
    "    @param input: string, input sentence in source language to be translated\n",
    "    @param max_length: the max # of words that the decoder can return\n",
    "    @output decoded_words: a list of words in target language\n",
    "    @output decoder_attentions: a list of vector, each of which sums up to 1.0\n",
    "    \"\"\"    \n",
    "    # process input sentence\n",
    "    with torch.no_grad():\n",
    "        # encode the source lanugage\n",
    "        encoder_hidden = encoder.initHidden(batch_size)\n",
    "        \n",
    "        max_input_len = max(input_len)\n",
    "#         max_target_len = max(target_len)\n",
    "        \n",
    "        encoder_outputs = torch.zeros([batch_size, max_input_len, encoder.hidden_size], device=device)\n",
    "    \n",
    "        encoder_output, encoder_hidden = encoder(input, input_len, encoder_hidden)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]]*batch_size, device=device)\n",
    "        # decode the context vector\n",
    "        decoder_hidden = encoder_hidden # decoder starts from the last encoding sentence\n",
    "        \n",
    "        # output of this function\n",
    "        decoded_words = []\n",
    "#         decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            # for each time step, the decoder network takes two inputs: previous outputs and the previous hidden states\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "#             decoded_words.append(topi.squeeze().detach().unsqueeze(1))\n",
    "#             pdb.set_trace()\n",
    "            decoded_words.append(topi.cpu().numpy())\n",
    "            decoder_input = topi.squeeze().detach().unsqueeze(1)  # detach from history as input\n",
    "\n",
    "#         pdb.set_trace()\n",
    "        return np.asarray(decoded_words).T#, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(encoder, decoder, data_loader):\n",
    "    total_score = 0\n",
    "    count = 0\n",
    "    for i, (input, input_len, target, target_len) in enumerate(data_loader):\n",
    "        decoded_words = evaluate(encoder, decoder, input, input_len)\n",
    "        candidate_sentences = []\n",
    "        for ind in range(decoded_words.shape[1]):\n",
    "            sent_words = []\n",
    "            for token in decoded_words[0][ind]:\n",
    "                if token != EOS_token:\n",
    "                    sent_words.append(train_output_lang.index2word[token])\n",
    "                else:\n",
    "                    break\n",
    "            sent_words = ' '.join(sent_words)\n",
    "#             sent_words = ' '.join([train_output_lang.index2word[token] for token in decoded_words[0][ind]])\n",
    "            candidate_sentences.append(sent_words)            \n",
    "#         print('candidate')\n",
    "        \n",
    "        reference_sentences = []\n",
    "        for sent in target:\n",
    "            sent_words = []\n",
    "            for token in sent:\n",
    "                if token.item() != EOS_token:\n",
    "                    sent_words.append(train_output_lang.index2word[token.item()])\n",
    "                else:\n",
    "                    break\n",
    "            sent_words = ' '.join(sent_words)\n",
    "#             sent_words = ' '.join([train_output_lang.index2word[token.item()] for token in sent])\n",
    "            reference_sentences.append(sent_words)\n",
    "#         print('reference')\n",
    "        \n",
    "        score = corpus_bleu(candidate_sentences, [reference_sentences], smooth='floor', smooth_floor=0.0, force=False)\n",
    "        \n",
    "        count += 1\n",
    "        total_score += score.score\n",
    "        if i == 10:\n",
    "            break\n",
    "    return total_score / float(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate\n",
      "reference\n",
      "candidate\n",
      "reference\n",
      "candidate\n",
      "reference\n",
      "candidate\n",
      "reference\n",
      "candidate\n",
      "reference\n",
      "candidate\n",
      "reference\n",
      "candidate\n",
      "reference\n",
      "candidate\n",
      "reference\n",
      "candidate\n",
      "reference\n",
      "candidate\n",
      "reference\n",
      "candidate\n",
      "reference\n"
     ]
    }
   ],
   "source": [
    "score = test(encoder,noattn_decoder,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    \"\"\"\n",
    "    Randomly select a English sentence from the dataset and try to produce its French translation.\n",
    "    Note that you need a correct implementation of evaluate() in order to make this function work.\n",
    "    \"\"\"    \n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(encoder1.state_dict(), \"encoder.pth\")\n",
    "# torch.save(attn_decoder1.state_dict(), \"attn_decoder.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder, noattn_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_bleu(sys_stream, ref_streams, smooth='exp', smooth_floor=0.0, force=False, lowercase=False,\n",
    "                tokenize=DEFAULT_TOKENIZER, use_effective_order=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.35533905932737\n"
     ]
    }
   ],
   "source": [
    "ref = [['this is   test']]\n",
    "candidates = ['this is a test']\n",
    "# score = sacrebleu.corpus_bleu(ref,candidates)\n",
    "score = sacrebleu.corpus_bleu(candidates,ref)\n",
    "print(score.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
