{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import io\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "import itertools\n",
    "import glob\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "from sacrebleu import corpus_bleu\n",
    "import sacrebleu\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "words_to_load = 100000\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_token = 2\n",
    "UNK_token = 3\n",
    "LR_RATE = 0.001\n",
    "MAX_LENGTH = 40\n",
    "hidden_size = 300\n",
    "teacher_forcing_ratio = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Preprocess Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"<pad>\", 3: \"<unk>\"}\n",
    "        self.n_words = 4  # Count SOS, EOS, pad and unk\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def normalizeZh(s):\n",
    "    s = s.strip()\n",
    "    s = re.sub(\"\\s+\", \" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPair(p):\n",
    "    filtered = []\n",
    "    for i in p:\n",
    "        filtered.append(' '.join(i.split()[:MAX_LENGTH-1]))\n",
    "    return filtered\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [filterPair(pair) for pair in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(dataset, lang1, lang2):\n",
    "    chinese = os.getcwd()+'/iwslt-zh-en/{}.tok.{}'.format(dataset, lang1)\n",
    "    english = os.getcwd()+'/iwslt-zh-en/{}.tok.{}'.format(dataset, lang2)\n",
    "\n",
    "    chinese_lines = open(chinese, encoding='utf-8').read().strip().split('\\n')\n",
    "    english_lines = open(english, encoding='utf-8').read().strip().split('\\n')\n",
    "    length = len(chinese_lines)\n",
    "\n",
    "    pairs = [[normalizeZh(chinese_lines[i]), normalizeString(english_lines[i])] for i in range(length)]\n",
    "    pairs = filterPairs(pairs)\n",
    "    \n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_lang, train_output_lang, train_pairs = readLangs('train', 'zh', 'en')\n",
    "val_input_lang, val_output_lang, val_pairs = readLangs('dev', 'zh', 'en')\n",
    "test_input_lang, test_output_lang, test_pairs = readLangs('test', 'zh', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86784"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49924"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213376"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pairs)  # 6621 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1261"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_pairs)  # 39 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1397"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Embedding__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding(ft_path, words_to_load):\n",
    "    fin = io.open(ft_path, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    vocab_size = words_to_load + 4\n",
    "    embedding_dim = d\n",
    "\n",
    "    embedding_mat = np.zeros((vocab_size, embedding_dim))\n",
    "    token2id = {}\n",
    "    id2token = {}\n",
    "    all_tokens = ['SOS', 'EOS', '<unk>', '<pad>']\n",
    "\n",
    "    for i, line in enumerate(fin):\n",
    "        if i >= words_to_load:\n",
    "            break\n",
    "        s = line.rstrip().split(' ')\n",
    "        embedding_mat[i+4, :] = np.asarray(s[1:])\n",
    "        token2id[s[0]] = i+4\n",
    "        id2token[i+4] = s[0]\n",
    "        all_tokens.append(s[0])\n",
    "\n",
    "    token2id['<pad>'] = PAD_token \n",
    "    token2id['<unk>'] = UNK_token\n",
    "    token2id['SOS'] = SOS_token\n",
    "    token2id['EOS'] = EOS_token\n",
    "    id2token[PAD_token] = '<pad>'\n",
    "    id2token[UNK_token] = '<unk>'\n",
    "    id2token[SOS_token] = 'SOS'\n",
    "    id2token[EOS_token] = 'EOS'\n",
    "    embedding_mat[PAD_token, :] = np.zeros((1,d))\n",
    "    #generate normal dist 1d array for UNK, SOS, EOS token\n",
    "    embedding_mat[UNK_token, :] = np.random.normal(size=d)\n",
    "    embedding_mat[SOS_token, :] = np.random.normal(size=d)\n",
    "    embedding_mat[EOS_token, :] = np.random.normal(size=d)\n",
    "        \n",
    "    return embedding_mat, all_tokens, token2id, id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_zh = os.getcwd()+'/wiki.zh.vec'\n",
    "fname_eng = '/'.join(os.getcwd().split('/')[:-1])+'/hw2/wiki-news-300d-1M.vec'\n",
    "embedding_mat_zh, all_tokens_zh, token2id_zh, id2token_zh = load_embedding(fname_zh, words_to_load)\n",
    "embedding_mat_en, all_tokens_en, token2id_en, id2token_en = load_embedding(fname_eng, words_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100004, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_mat_zh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100004, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_mat_en.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Loader__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_lang, output_lang, pairs):\n",
    "        \"\"\"\n",
    "        @param data_list_1: list of sentence 1 tokens \n",
    "        @param data_list_2: list of sentence 2 tokens\n",
    "        @param target_list: list of review targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.input_w2i = input_lang\n",
    "        self.output_w2i = output_lang\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        input_sentence = self.pairs[key][0]\n",
    "        input_indexes = [self.input_w2i[word] if word in self.input_w2i else UNK_token for word in input_sentence.split(' ')]\n",
    "        input_indexes.append(EOS_token)\n",
    "        input_length = len(input_indexes)\n",
    "\n",
    "        output_sentence = self.pairs[key][1]\n",
    "        output_indexes = [self.output_w2i[word] if word in self.output_w2i else UNK_token for word in output_sentence.split(' ')]\n",
    "        output_indexes.append(EOS_token)\n",
    "        output_length = len(output_indexes)\n",
    "        return [input_indexes, input_length, output_indexes, output_length]\n",
    "\n",
    "    \n",
    "def NMTDataset_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    input_ls = []\n",
    "    output_ls = []\n",
    "    input_length_ls = []\n",
    "    output_length_ls = []\n",
    "    \n",
    "    for datum in batch:\n",
    "        input_length_ls.append(datum[1])\n",
    "        output_length_ls.append(datum[3])\n",
    "    \n",
    "    #find max length in each batch\n",
    "    max_input = sorted(input_length_ls)[-1]\n",
    "    max_output = sorted(output_length_ls)[-1]\n",
    "    \n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec_input = np.pad(np.array(datum[0]), \n",
    "                                  pad_width=((0,MAX_LENGTH-datum[1])), \n",
    "                                  mode=\"constant\", constant_values=2).tolist()\n",
    "        padded_vec_output = np.pad(np.array(datum[2]), \n",
    "                                   pad_width=((0,MAX_LENGTH-datum[3])), \n",
    "                                   mode=\"constant\", constant_values=2).tolist()\n",
    "        input_ls.append(padded_vec_input)\n",
    "        output_ls.append(padded_vec_output)\n",
    "    return [torch.tensor(torch.from_numpy(np.array(input_ls)), device=device), \n",
    "            torch.tensor(input_length_ls, device=device), \n",
    "            torch.tensor(torch.from_numpy(np.array(output_ls)), device=device), \n",
    "            torch.tensor(output_length_ls, device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pytorch dataloader\n",
    "train_dataset = NMTDataset(token2id_zh, token2id_en, train_pairs)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size,\n",
    "                                           collate_fn=NMTDataset_collate_func,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)\n",
    "\n",
    "val_dataset = NMTDataset(token2id_zh, token2id_en, val_pairs)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         collate_fn=NMTDataset_collate_func,\n",
    "                                         shuffle=False,\n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 40])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(val_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in val_loader:\n",
    "#     print(i)\n",
    "    if i[0].shape[1] != 40:\n",
    "        print(True)\n",
    "#     print(i[0].shape)\n",
    "#     for ind in i[2]:\n",
    "#         for token in ind:\n",
    "#             print(token)\n",
    "#             print(train_output_lang.index2word[token.item()])\n",
    "#     for ind in i[2]:\n",
    "#         print(' '.join(train_output_lang.index2word[token.item()] for token in ind))\n",
    "#     print([train_output_lang.index2word[token.item()] for ind in i[2] for token in ind])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Encoder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        embed_mat = torch.from_numpy(embedding_mat_zh).float()\n",
    "        n, embed_dim = embed_mat.shape\n",
    "#         mask = np.zeros((n,1))\n",
    "#         mask[0] = 1\n",
    "#         mask[1] = 1\n",
    "#         mask[2] = 1\n",
    "#         mask[3] = 1\n",
    "#         mask = torch.from_numpy(mask).float()\n",
    "#         self.mask_embedding = nn.Embedding.from_pretrained(mask, freeze = False)\n",
    "        self.embedding = nn.Embedding.from_pretrained(embed_mat, freeze = True)\n",
    "        \n",
    "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input, input_len, hidden):\n",
    "        # Compute sorted sequence lengths\n",
    "#         _, idx_sort = torch.sort(input_len, dim=0, descending=True)\n",
    "#         _, idx_unsort = torch.sort(idx_sort, dim=0)\n",
    "        \n",
    "        # get embedding of characters\n",
    "        embed = self.embedding(input)\n",
    "#         mask = self.mask_embedding(input)\n",
    "        \n",
    "#         embedded = mask*embed + (1-mask)*embed.clone().detach()\n",
    "        embedded = embed\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        \n",
    "        # Sort embedding and length\n",
    "#         embedded = embedded.index_select(0, idx_sort)\n",
    "#         input_len = input_len.index_select(0, idx_sort)\n",
    "        \n",
    "#         packed_emb = nn.utils.rnn.pack_padded_sequence(embedded, input_len.cpu().numpy(), batch_first=True)\n",
    "#         packed_output, hidden = self.gru(packed_emb, hidden)\n",
    "#         output, output_lens =  nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        # Unsort output and last hidden unit\n",
    "#         output = output.index_select(0, idx_unsort)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, hidden_size, kernel_dim, batch_size):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        embed_mat = torch.from_numpy(embedding_mat_zh).float()\n",
    "        n, embed_dim = embed_mat.shape\n",
    "#         mask = np.zeros((n,1))\n",
    "#         mask[0] = 1\n",
    "#         mask[1] = 1\n",
    "#         mask[2] = 1\n",
    "#         mask[3] = 1\n",
    "#         mask = torch.from_numpy(mask).float()\n",
    "#         self.mask_embedding = nn.Embedding.from_pretrained(mask, freeze = False)\n",
    "        self.embedding = nn.Embedding.from_pretrained(embed_mat, freeze = True)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(embed_dim, hidden_size*2, kernel_size=kernel_dim, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_size*2, hidden_size*2, kernel_size=kernel_dim, padding=1)\n",
    "        self.linear1 = nn.Linear(hidden_size*2, hidden_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # get embedding of words\n",
    "        embed = self.embedding(input)\n",
    "#         mask = self.mask_embedding(input)\n",
    "        \n",
    "#         embedded = mask*embed + (1-mask)*embed.clone().detach()\n",
    "        embedded = embed\n",
    "    \n",
    "        # perform convolution 1\n",
    "        hidden = self.conv1(embedded.transpose(1,2)).transpose(1,2)\n",
    "        hidden = F.relu(hidden)\n",
    "#         hidden = F.relu(hidden.contiguous().view(-1, hidden.size(-1))).view(batch_size, hidden.size(1), hidden.size(-1))\n",
    "\n",
    "        # perform convolution 2\n",
    "        hidden = self.conv2(hidden.transpose(1,2)).transpose(1,2)\n",
    "        hidden = F.relu(hidden)\n",
    "#         hidden = F.relu(hidden.contiguous().view(-1, hidden.size(-1))).view(batch_size, hidden.size(1), hidden.size(-1))\n",
    "\n",
    "        hidden,_ = hidden.max(dim=1)\n",
    "        out = self.linear1(hidden)\n",
    "        out = out.view(1,out.size(0),out.size(1))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Decoder Without Attention__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        embed_mat = torch.from_numpy(embedding_mat_en).float()\n",
    "        n, embed_dim = embed_mat.shape\n",
    "#         mask = np.zeros((n,1))\n",
    "#         mask[0] = 1\n",
    "#         mask[1] = 1\n",
    "#         mask[2] = 1\n",
    "#         mask[3] = 1\n",
    "#         mask = torch.from_numpy(mask).float()\n",
    "#         self.mask_embedding = nn.Embedding.from_pretrained(mask, freeze = False)\n",
    "        self.embedding = nn.Embedding.from_pretrained(embed_mat, freeze = True)\n",
    "        \n",
    "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, word_input, hidden):\n",
    "        # get embedding of words\n",
    "        embed = self.embedding(word_input)\n",
    "#         mask = self.mask_embedding(word_input)\n",
    "        \n",
    "#         embedded = mask*embed + (1-mask)*embed.clone().detach()\n",
    "        embedded = embed\n",
    "#         print(embedded.size())\n",
    "    \n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        \n",
    "        # Final output layer\n",
    "        output = output.squeeze(1) # B x N\n",
    "        output = self.linear(output)\n",
    "        output = self.softmax(output)\n",
    "\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers=1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers \n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        embed_mat = torch.from_numpy(embedding_mat_zh).float()\n",
    "        n, embed_dim = embed_mat.shape\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(embed_mat, freeze=True)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "\n",
    "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        \n",
    "        ### embed: [batch size * 1 * emb_dim = 300 ] ###\n",
    "        ### hidden: [batch size * 1 * hidden_size = 300 ] ###\n",
    "        ### encoder_outputs: [batch size * max_sentence_length_zh * hidden_size = 300 ] ###\n",
    "        ### 因为这里concat之后，attn layer 他给的是 hidden size *2 \n",
    "        ### 所以我这儿的hidden size就只能写300了 \n",
    "        \n",
    "        embed = self.embedding(input)\n",
    "        embed = self.dropout(embed)   \n",
    "        \n",
    "        \n",
    "        ### torch.cat((embed, hidden), 2)  \n",
    "        ### [batch size * 1 * (emb_dim + hidden_size) ]\n",
    "        \n",
    "        ### attn_weights: [batch size * 1 * max_sentence_length_zh ]###\n",
    "        \n",
    "        ### softmax dim=2 因为最后一个dimension是 词组什么的，不能是1，1的话就是\n",
    "        ### 不同batch间这样比较了？\n",
    "        \n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embed, hidden.squeeze(0).unsqueeze(1)), 2)), dim=2)\n",
    "        \n",
    "\n",
    "        ### torch.bmm(attn_weights[0].unsqueeze(1),encoder_outputs).squeeze(1) :\n",
    "        ### [batch size * 1 * hidden_size ]###\n",
    "\n",
    "        ### attn_applied: [batch size * hidden_size (= 300) ] ###\n",
    "#         pdb.set_trace()\n",
    "#         print(attn_weights.size())\n",
    "#         print(encoder_outputs.size())\n",
    "        attn_applied = torch.bmm(attn_weights, encoder_outputs).squeeze(1)\n",
    "        \n",
    "        ### output: [batch size * hidden_size (= 300) ] ###\n",
    "        ### embed[0]: [batch size * hidden_size (= 300) ] ###\n",
    "\n",
    "        output = torch.cat((embed.squeeze(1), attn_applied), 1)\n",
    " \n",
    "        ### output: [batch size * 1 * hidden_size (= 300) ] ###\n",
    "        output = self.attn_combine(output).unsqueeze(1)\n",
    "        \n",
    "        ### output: [batch size * 1 * hidden_size (= 300) ] ###\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        ### output: [batch size * 1 * hidden_size (= 300) ] ###\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output.squeeze(1)))\n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self,batch_size):\n",
    "        return torch.randn(self.num_layers, batch_size, self.hidden_size,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Attn(nn.Module):\n",
    "#     def __init__(self, method, hidden_size):\n",
    "#         super(Attn, self).__init__()\n",
    "#         self.method = method\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "#         self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "#         stdv = 1. / math.sqrt(self.v.size(0))\n",
    "#         self.v.data.normal_(mean=0, std=stdv)\n",
    "\n",
    "#     def forward(self, hidden, encoder_outputs, src_len=None):\n",
    "#         '''\n",
    "#         :param hidden: \n",
    "#             previous hidden state of the decoder, in shape (layers*directions,B,H)\n",
    "#         :param encoder_outputs:\n",
    "#             encoder outputs from Encoder, in shape (T,B,H)\n",
    "#         :param src_len:\n",
    "#             used for masking. NoneType or tensor in shape (B) indicating sequence length\n",
    "#         :return\n",
    "#             attention energies in shape (B,T)\n",
    "#         '''\n",
    "#         max_len = encoder_outputs.size(1)\n",
    "#         this_batch_size = encoder_outputs.size(1)\n",
    "#         H = hidden.repeat(max_len,1,1).transpose(0,1)\n",
    "# #         encoder_outputs = encoder_outputs.transpose(0,1) # [B*T*H]\n",
    "#         attn_energies = self.score(H,encoder_outputs) # compute attention score\n",
    "        \n",
    "#         if src_len is not None:\n",
    "#             mask = []\n",
    "#             for b in range(src_len.size(0)):\n",
    "#                 mask.append([0] * src_len[b].item() + [1] * (encoder_outputs.size(1) - src_len[b].item()))\n",
    "#             mask = cuda_(torch.ByteTensor(mask).unsqueeze(1)) # [B,1,T]\n",
    "#             attn_energies = attn_energies.masked_fill(mask, -1e18)\n",
    "        \n",
    "#         return F.softmax(attn_energies, dim = 1).unsqueeze(1) # normalize with softmax\n",
    "\n",
    "#     def score(self, hidden, encoder_outputs):\n",
    "#         energy = torch.tanh(self.attn(torch.cat([hidden, encoder_outputs], 2))) # [B*T*2H]->[B*T*H]\n",
    "#         energy = energy.transpose(2,1) # [B*H*T]\n",
    "#         v = self.v.repeat(encoder_outputs.data.shape[0],1).unsqueeze(1) #[B*1*H]\n",
    "#         energy = torch.bmm(v,energy) # [B*1*T]\n",
    "#         return energy.squeeze(1) #[B*T]\n",
    "\n",
    "# class BahdanauAttnDecoderRNN(nn.Module):\n",
    "#     def __init__(self, weights_matrix, hidden_size, embed_size, output_size, dropout_p=0.5):\n",
    "#         super(BahdanauAttnDecoderRNN, self).__init__()\n",
    "#         # Define parameters\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.embed_size = embed_size\n",
    "#         self.output_size = output_size\n",
    "#         self.dropout_p = dropout_p\n",
    "#         # Define layers\n",
    "        \n",
    "#         embed_mat = torch.from_numpy(weights_matrix).float()\n",
    "#         self.num_embeddings, self.embedding_dim = embed_mat.shape\n",
    "#         mask = np.zeros((self.num_embeddings,1))\n",
    "#         mask[0] = 1\n",
    "#         mask[1] = 1\n",
    "#         mask[2] = 1\n",
    "#         mask[3] = 1\n",
    "#         mask = torch.from_numpy(mask).float()\n",
    "#         self.mask_embedding = nn.Embedding.from_pretrained(mask, freeze = False)\n",
    "#         self.embedding = nn.Embedding.from_pretrained(embed_mat, freeze = True)\n",
    "#         self.dropout = nn.Dropout(dropout_p)\n",
    "#         self.attn = Attn('concat', hidden_size)\n",
    "#         self.gru = nn.GRU(hidden_size + self.embedding_dim, hidden_size, dropout=dropout_p)\n",
    "#         #self.attn_combine = nn.Linear(hidden_size + embed_size, hidden_size)\n",
    "#         self.out = nn.Linear(hidden_size, self.output_size)\n",
    "\n",
    "#     def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "#         '''\n",
    "#         :param word_input:\n",
    "#             word input for current time step, in shape (B)\n",
    "#         :param last_hidden:\n",
    "#             last hidden stat of the decoder, in shape (layers*direction*B*H)\n",
    "#         :param encoder_outputs:\n",
    "#             encoder outputs in shape (T*B*H)\n",
    "#         :return\n",
    "#             decoder output\n",
    "#         Note: we run this one step at a time i.e. you should use a outer loop \n",
    "#             to process the whole sequence\n",
    "#         Tip(update):\n",
    "#         EncoderRNN may be bidirectional or have multiple layers, so the shape of hidden states can be \n",
    "#         different from that of DecoderRNN\n",
    "#         You may have to manually guarantee that they have the same dimension outside this function,\n",
    "#         e.g, select the encoder hidden state of the foward/backward pass.\n",
    "#         '''\n",
    "#         # Get the embedding of the current input word (last output word)\n",
    "#         embed = self.embedding(word_input)\n",
    "#         mask = self.mask_embedding(word_input)\n",
    "        \n",
    "#         word_embedded = mask*embed + (1-mask)*embed.clone().detach()\n",
    "#         word_embedded = self.embedding(word_input).view(word_input.size(0), 1, -1) # (1,B,V)\n",
    "#         word_embedded = self.dropout(word_embedded)\n",
    "#         # Calculate attention weights and apply to encoder outputs\n",
    "#         attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
    "#         context = attn_weights.bmm(encoder_outputs)  # (B,1,V)\n",
    "# #         context = context.transpose(0, 1)  # (1,B,V)\n",
    "#         # Combine embedded input word and attended context, run through RNN\n",
    "#         rnn_input = torch.cat((word_embedded, context), 2)\n",
    "#         #rnn_input = self.attn_combine(rnn_input) # use it in case your size of rnn_input is different\n",
    "#         output, hidden = self.gru(rnn_input.transpose(0, 1), last_hidden)\n",
    "#         output = output.squeeze(0)  # (1,B,V)->(B,V)\n",
    "#         # context = context.squeeze(0)\n",
    "#         # update: \"context\" input before final layer can be problematic.\n",
    "#         # output = F.log_softmax(self.out(torch.cat((output, context), 1)))\n",
    "#         output = F.log_softmax(self.out(output), dim = 1)\n",
    "#         # Return final output, hidden state\n",
    "#         return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input, target, input_len, target_len, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, teach_forcing_ratio=0.5, encoder_cnn = False):\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    max_input_len = max(input_len)\n",
    "    max_target_len = max(target_len)\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    if not encoder_cnn:\n",
    "        encoder_hidden = encoder.initHidden(batch_size)\n",
    "        encoder_output, encoder_hidden = encoder(input, input_len, encoder_hidden)\n",
    "#         print(encoder_output.size())\n",
    "    else:\n",
    "        encoder_hidden = encoder(input)\n",
    "        \n",
    "    decoder_input = torch.tensor([[SOS_token]]*batch_size, device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(max_target_len):\n",
    "#             decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "            loss += criterion(decoder_output, target[:,di])\n",
    "            decoder_input = target[:,di].unsqueeze(1)  # Teacher forcing (batch_size, 1)\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(max_target_len):\n",
    "#             decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "            loss += criterion(decoder_output, target[:,di])\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach().unsqueeze(1)  # detach from history as input\n",
    "    #         if decoder_input.item() == EOS_token:\n",
    "    #             break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / float(max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(loader, encoder, decoder, n_iters, encoder_cnn, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    best_bleu = None\n",
    "    save_path = os.getcwd() + '/saved_model/En-RNN-De-Attn-Nomask.pt'\n",
    "            \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        for i, (input, input_len, target, target_len) in enumerate(train_loader):\n",
    "            loss = train(input, target, input_len, target_len, encoder, decoder, \n",
    "                         encoder_optimizer, decoder_optimizer, criterion, \n",
    "                         teach_forcing_ratio=teacher_forcing_ratio, encoder_cnn = encoder_cnn)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "            \n",
    "            \n",
    "            if i % print_every == 0:\n",
    "                current_bleu = test(encoder, decoder, val_loader, encoder_cnn)\n",
    "                if not best_bleu or current_bleu > best_bleu:\n",
    "                    torch.save({\n",
    "                                'epoch': iter,\n",
    "                                'encoder_state_dict': encoder.state_dict(),\n",
    "                                'decoder_state_dict': decoder.state_dict(),\n",
    "                                'encoder_optimizer_state_dict': encoder_optimizer.state_dict(),\n",
    "                                'decoder_optimizer_state_dict': decoder_optimizer.state_dict(),\n",
    "                                'train_loss': loss,\n",
    "                                'best_BLEU': best_bleu\n",
    "                                }, save_path)\n",
    "                    best_bleu = current_bleu\n",
    "                \n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (Epoch: %d %d%%) | Train Loss: %.4f | Best Bleu: %.4f | Current Bleu: %.4f' \n",
    "                      % (timeSince(start, iter / n_iters), iter, iter / n_iters * 100, print_loss_avg, best_bleu, current_bleu))\n",
    "\n",
    "            if i % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "#     showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, input, input_len, encoder_cnn):\n",
    "    with torch.no_grad():\n",
    "#         for i, (input, input_len, target, target_len) in enumerate(data_loader):\n",
    "        max_input_len = max(input_len)\n",
    "\n",
    "        if not encoder_cnn:\n",
    "            encoder_hidden = encoder.initHidden(batch_size)\n",
    "            encoder_output, encoder_hidden = encoder(input, input_len, encoder_hidden)\n",
    "        else:\n",
    "            encoder_hidden = encoder(input)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]]*batch_size, device=device)\n",
    "        decoder_hidden = encoder_hidden # decoder starts from the last encoding sentence\n",
    "\n",
    "        # output of this function\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_input_len):\n",
    "            # for each time step, the decoder network takes two inputs: previous outputs and the previous hidden states\n",
    "#             decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            \n",
    "#             pdb.set_trace()\n",
    "\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoded_words.append(topi.cpu().numpy())\n",
    "            decoder_input = topi.squeeze().detach().unsqueeze(1)  # detach from history as input\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        return np.asarray(decoded_words).T#, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(encoder, decoder, data_loader, encoder_cnn):\n",
    "    total_score = 0\n",
    "    count = 0\n",
    "    check = 0\n",
    "    \n",
    "    candidate_corpus = []\n",
    "    reference_corpus = []\n",
    "\n",
    "    for i, (input, input_len, target, target_len) in enumerate(data_loader):\n",
    "        decoded_words = evaluate(encoder, decoder, input, input_len, encoder_cnn)\n",
    "        candidate_sentences = []\n",
    "        for ind in range(decoded_words.shape[1]):\n",
    "            sent_words = []\n",
    "            for token in decoded_words[0][ind]:\n",
    "                if token != PAD_token and token != EOS_token:\n",
    "                    sent_words.append(id2token_en[token])\n",
    "                else:\n",
    "                    break\n",
    "            sent_words = ' '.join(sent_words)\n",
    "            if check == 0:\n",
    "                print('predict: '+sent_words)\n",
    "                check += 1\n",
    "            candidate_sentences.append(sent_words)\n",
    "#         candidate_corpus.extend(candidate_sentences)\n",
    "\n",
    "        reference_sentences = []\n",
    "        for sent in target:\n",
    "            sent_words = []\n",
    "            for token in sent:\n",
    "                if token.item() != EOS_token:\n",
    "                    sent_words.append(id2token_en[token.item()])\n",
    "                else:\n",
    "                    break\n",
    "            sent_words = ' '.join(sent_words)\n",
    "            if check == 1:\n",
    "                print('target: '+sent_words)\n",
    "                check += 1\n",
    "            reference_sentences.append(sent_words)\n",
    "#         reference_corpus.extend(reference_sentences)\n",
    "        count += 1\n",
    "        score = corpus_bleu(candidate_sentences, [reference_sentences], smooth='exp', smooth_floor=0.0, force=False).score\n",
    "        total_score += score\n",
    "    return total_score / float(count)\n",
    "\n",
    "#     score = corpus_bleu(candidate_sentences, [reference_sentences], smooth='exp', smooth_floor=0.0, force=False).score\n",
    "#     return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: \n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "0m 13s (- 4m 17s) (Epoch: 1 5%) | Train Loss: 0.0115 | Best Bleu: 0.0000 | Current Bleu: 0.0000\n",
      "predict: and <unk> s <unk> s the <unk> the the the the the <unk> the the\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "11m 29s (- 218m 13s) (Epoch: 1 5%) | Train Loss: 3.2231 | Best Bleu: 4.6632 | Current Bleu: 4.6632\n",
      "predict: i i <unk> i i i to the i .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "22m 41s (- 431m 13s) (Epoch: 1 5%) | Train Loss: 2.9468 | Best Bleu: 4.6632 | Current Bleu: 3.6162\n",
      "predict: i i <unk> t i i <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "33m 57s (- 645m 19s) (Epoch: 1 5%) | Train Loss: 2.8501 | Best Bleu: 5.0300 | Current Bleu: 5.0300\n",
      "predict: i <unk> m <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "45m 13s (- 859m 13s) (Epoch: 1 5%) | Train Loss: 2.7987 | Best Bleu: 5.8117 | Current Bleu: 5.8117\n",
      "predict: i <unk> m <unk> i <unk> <unk> i <unk> <unk> <unk> <unk> .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "56m 29s (- 1073m 20s) (Epoch: 1 5%) | Train Loss: 2.7395 | Best Bleu: 6.1415 | Current Bleu: 6.1415\n",
      "predict: i was a a and i i and i i and i i .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "67m 44s (- 1287m 14s) (Epoch: 1 5%) | Train Loss: 2.6966 | Best Bleu: 6.1415 | Current Bleu: 3.8808\n",
      "predict: i <unk> m <unk> <unk> <unk> <unk> <unk> <unk> <unk> . . .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "75m 18s (- 677m 44s) (Epoch: 2 10%) | Train Loss: 1.7853 | Best Bleu: 6.1415 | Current Bleu: 5.3401\n",
      "predict: i i i i i i i i and i my i and i .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "86m 32s (- 778m 51s) (Epoch: 2 10%) | Train Loss: 2.6032 | Best Bleu: 6.1415 | Current Bleu: 5.2523\n",
      "predict: i i <unk> i i i i <unk> <unk> i <unk> <unk> .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "97m 45s (- 879m 51s) (Epoch: 2 10%) | Train Loss: 2.5721 | Best Bleu: 6.2493 | Current Bleu: 6.2493\n",
      "predict: i remember <unk> i <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> i <unk> <unk> <unk>\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "109m 0s (- 981m 5s) (Epoch: 2 10%) | Train Loss: 2.5621 | Best Bleu: 6.2493 | Current Bleu: 5.0249\n",
      "predict: i remember remember in the morning and i was a little bit of my .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "120m 13s (- 1081m 59s) (Epoch: 2 10%) | Train Loss: 2.5201 | Best Bleu: 6.2493 | Current Bleu: 5.8556\n",
      "predict: i remember to remember to remember out and i remember a little bit of the night .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "131m 27s (- 1183m 11s) (Epoch: 2 10%) | Train Loss: 2.5196 | Best Bleu: 6.3529 | Current Bleu: 6.3529\n",
      "predict: i remember remember in the morning and i remember that i was a little bit of my life .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "142m 41s (- 1284m 14s) (Epoch: 2 10%) | Train Loss: 2.4877 | Best Bleu: 6.3529 | Current Bleu: 5.8239\n",
      "predict: i remember i was a to of the and and . .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "150m 13s (- 851m 18s) (Epoch: 3 15%) | Train Loss: 1.6574 | Best Bleu: 6.3529 | Current Bleu: 5.9581\n",
      "predict: i remember my wife in the morning and i was a little bit of my .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "161m 27s (- 914m 53s) (Epoch: 3 15%) | Train Loss: 2.4463 | Best Bleu: 6.3529 | Current Bleu: 5.4593\n",
      "predict: i remember i <unk> s the <unk> i and i i and i i to\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "172m 40s (- 978m 29s) (Epoch: 3 15%) | Train Loss: 2.4490 | Best Bleu: 6.3529 | Current Bleu: 5.2965\n",
      "predict: i remember remember to remember the night and i remember that i was a\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "183m 53s (- 1042m 0s) (Epoch: 3 15%) | Train Loss: 2.4123 | Best Bleu: 6.3529 | Current Bleu: 5.0476\n",
      "predict: i remember remember to remember the night of the night and i remember remember to tell her story .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "195m 7s (- 1105m 43s) (Epoch: 3 15%) | Train Loss: 2.4251 | Best Bleu: 6.3529 | Current Bleu: 5.8588\n",
      "predict: i remember remember remember to remember and remember and remember and i remember to remember .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "206m 20s (- 1169m 15s) (Epoch: 3 15%) | Train Loss: 2.4102 | Best Bleu: 6.3529 | Current Bleu: 5.2901\n",
      "predict: i remember remember in the night of the night and i remember to\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "217m 33s (- 1232m 47s) (Epoch: 3 15%) | Train Loss: 2.3991 | Best Bleu: 6.3529 | Current Bleu: 6.0485\n",
      "predict: i remember remember to the <unk> and i and <unk> <unk> and <unk> .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "225m 5s (- 900m 23s) (Epoch: 4 20%) | Train Loss: 1.6056 | Best Bleu: 6.3529 | Current Bleu: 5.1817\n",
      "predict: i remember remember the night and the night and and the the the . .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "236m 19s (- 945m 17s) (Epoch: 4 20%) | Train Loss: 2.3555 | Best Bleu: 6.3529 | Current Bleu: 5.7296\n",
      "predict: i remember remember remember heard in the morning of the night and i hear the voice of the voice .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "247m 32s (- 990m 8s) (Epoch: 4 20%) | Train Loss: 2.3424 | Best Bleu: 6.3529 | Current Bleu: 6.0139\n",
      "predict: i remember remember remember remember remember remember remember remember night and remember remember and remember and i <unk>\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "258m 43s (- 1034m 55s) (Epoch: 4 20%) | Train Loss: 2.3409 | Best Bleu: 6.3529 | Current Bleu: 5.3458\n",
      "predict: i remember remember remember remember remember remember heard in the morning of the and . .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "269m 57s (- 1079m 51s) (Epoch: 4 20%) | Train Loss: 2.3521 | Best Bleu: 6.3529 | Current Bleu: 5.4568\n",
      "predict: i remember remember remember remember and remember the night and remember the and and\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "281m 11s (- 1124m 47s) (Epoch: 4 20%) | Train Loss: 2.3658 | Best Bleu: 6.3529 | Current Bleu: 6.2157\n",
      "predict: remember remember i remember in the morning night night night and the the\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "292m 27s (- 1169m 48s) (Epoch: 4 20%) | Train Loss: 2.3754 | Best Bleu: 6.3529 | Current Bleu: 4.3164\n",
      "predict: i remember remember <unk> remember night and remember and i remember to the . .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "299m 59s (- 899m 58s) (Epoch: 5 25%) | Train Loss: 1.5629 | Best Bleu: 6.3529 | Current Bleu: 6.0399\n",
      "predict: i remember remember remember remember the remember day and remember the sound of the voice voice .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "311m 12s (- 933m 37s) (Epoch: 5 25%) | Train Loss: 2.2826 | Best Bleu: 6.3529 | Current Bleu: 5.6503\n",
      "predict: i remember remember remember and remember remember and i remember the voice .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "322m 25s (- 967m 15s) (Epoch: 5 25%) | Train Loss: 2.2860 | Best Bleu: 6.3529 | Current Bleu: 5.9029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: i remember remember remember night and remember night and remember the .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "333m 39s (- 1000m 59s) (Epoch: 5 25%) | Train Loss: 2.3107 | Best Bleu: 6.3529 | Current Bleu: 6.3138\n",
      "predict: remember remember days days days days and remember and the and .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "344m 55s (- 1034m 45s) (Epoch: 5 25%) | Train Loss: 2.3320 | Best Bleu: 6.3529 | Current Bleu: 5.5061\n",
      "predict: i remember remember i remember heard and i remember the night and i heard the . .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "356m 8s (- 1068m 25s) (Epoch: 5 25%) | Train Loss: 2.3256 | Best Bleu: 6.3529 | Current Bleu: 5.7908\n",
      "predict: i remember remember remember remember remember and remember the day and i remember the . .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "367m 21s (- 1102m 3s) (Epoch: 5 25%) | Train Loss: 2.2864 | Best Bleu: 6.3529 | Current Bleu: 5.9201\n",
      "predict: i remember remember remember remember remember remember day and remember the day .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "374m 55s (- 874m 50s) (Epoch: 6 30%) | Train Loss: 1.5565 | Best Bleu: 6.3529 | Current Bleu: 5.3004\n",
      "predict: i remember remember remember year old and and remember and and remember and . .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "386m 7s (- 900m 56s) (Epoch: 6 30%) | Train Loss: 2.2324 | Best Bleu: 6.3529 | Current Bleu: 5.4503\n",
      "predict: i remember remember remember to remember night and remember the day and the the .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "397m 20s (- 927m 7s) (Epoch: 6 30%) | Train Loss: 2.2644 | Best Bleu: 6.3529 | Current Bleu: 6.2107\n",
      "predict: i remember remember remember remember remember night and remember the night and remember the night .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "408m 33s (- 953m 17s) (Epoch: 6 30%) | Train Loss: 2.2725 | Best Bleu: 6.3529 | Current Bleu: 6.2268\n",
      "predict: i remember remember to remember remember and remember the night of the night .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "419m 45s (- 979m 25s) (Epoch: 6 30%) | Train Loss: 2.2400 | Best Bleu: 6.3529 | Current Bleu: 5.7210\n",
      "predict: i remember remember remember remember day and remember day and the\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "430m 56s (- 1005m 32s) (Epoch: 6 30%) | Train Loss: 2.2687 | Best Bleu: 6.3529 | Current Bleu: 6.2320\n",
      "predict: i remember remember remember remember day and remember the day and hear .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "442m 7s (- 1031m 37s) (Epoch: 6 30%) | Train Loss: 2.2734 | Best Bleu: 6.3529 | Current Bleu: 5.7819\n",
      "predict: i remember remember remember to remember and remember and remember and remember and remember to\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "449m 39s (- 835m 5s) (Epoch: 7 35%) | Train Loss: 1.5259 | Best Bleu: 6.4751 | Current Bleu: 6.4751\n",
      "predict: i remember remember night remember and remember day the night and the the the .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "460m 50s (- 855m 51s) (Epoch: 7 35%) | Train Loss: 2.2164 | Best Bleu: 6.4751 | Current Bleu: 6.0409\n",
      "predict: i remember remember remember remember remember to remember and remember and remember and i <unk>\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "472m 2s (- 876m 39s) (Epoch: 7 35%) | Train Loss: 2.2239 | Best Bleu: 6.6817 | Current Bleu: 6.6817\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(hidden_size=hidden_size).to(device)\n",
    "# encoder = EncoderCNN(hidden_size,kernel_dim=3,batch_size=batch_size).to(device)\n",
    "# noattn_decoder = DecoderRNN(hidden_size, embedding_mat_zh.shape[0]).to(device)\n",
    "attn_decoder = AttnDecoderRNN(hidden_size, embedding_mat_zh.shape[0]).to(device)\n",
    "# attn_decoder1 = BahdanauAttnDecoderRNN(hidden_size, output_lang.n_words, n_layers=1, dropout_p=0.1).to(device)\n",
    "\n",
    "#UNCOMMENT TO TRAIN THE MODEL\n",
    "trainIters(train_loader, encoder, attn_decoder, n_iters=20, encoder_cnn=False, print_every=1000, plot_every=1, learning_rate=LR_RATE)\n",
    "# trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\n",
    "\n",
    "# encoder.load_state_dict(torch.load(\"encoder.pth\"))\n",
    "# attn_decoder1.load_state_dict(torch.load(\"attn_decoder.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_bleu(sys_stream, ref_streams, smooth='exp', smooth_floor=0.0, force=False, lowercase=False,\n",
    "                tokenize=DEFAULT_TOKENIZER, use_effective_order=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.35533905932737\n"
     ]
    }
   ],
   "source": [
    "ref = [['this is   test']]\n",
    "candidates = ['this is a test']\n",
    "# score = sacrebleu.corpus_bleu(ref,candidates)\n",
    "score = sacrebleu.corpus_bleu(candidates,ref)\n",
    "print(score.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.getcwd() + '/saved_model/En-RNN-De-NoAttn.pt'\n",
    "device = torch.device(\"cuda\")\n",
    "checkpoint = torch.load(save_path)\n",
    "en = EncoderRNN(train_input_lang.n_words, hidden_size=128).to(device)\n",
    "de = DecoderRNN(hidden_size=128, output_size=train_output_lang.n_words).to(device)\n",
    "en.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "de.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "bleu = checkpoint['best_BLEU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.getcwd() + '/saved_model/En-RNN-De-Attn-Nomask.pt'\n",
    "device = torch.device(\"cuda\")\n",
    "checkpoint = torch.load(save_path)\n",
    "encoder = EncoderRNN(hidden_size=hidden_size).to(device)\n",
    "attn_decoder = AttnDecoderRNN(hidden_size, embedding_mat_zh.shape[0]).to(device)\n",
    "encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "attn_decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "bleu = checkpoint['best_BLEU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.getcwd() + '/saved_model/En-CNN-De-NoAttn.pt'\n",
    "device = torch.device(\"cuda\")\n",
    "checkpoint = torch.load(save_path)\n",
    "cnn_en = EncoderCNN(hidden_size=128,kernel_dim=3,batch_size=batch_size).to(device)\n",
    "cnn_de = DecoderRNN(hidden_size=128,output_size=42228).to(device)\n",
    "cnn_en.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "cnn_de.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "bleu = checkpoint['best_BLEU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_val(encoder, decoder, data_loader, encoder_cnn):\n",
    "    total_score = 0\n",
    "    count = 0\n",
    "    check = 0\n",
    "    \n",
    "    candidate_corpus = []\n",
    "    reference_corpus = []\n",
    "\n",
    "    for i, (input, input_len, target, target_len) in enumerate(data_loader):\n",
    "        candidate_sentences = []\n",
    "        decoded_words = evaluate(encoder, decoder, input, input_len, encoder_cnn)\n",
    "        for ind in range(decoded_words.shape[1]):\n",
    "            sent_words = []\n",
    "            for token in decoded_words[0][ind]:\n",
    "                if token != PAD_token and token != EOS_token:\n",
    "                    sent_words.append(train_output_lang.index2word[token])\n",
    "                else:\n",
    "                    break\n",
    "            sent_words = ' '.join(sent_words)\n",
    "            candidate_sentences.append(sent_words)\n",
    "#         candidate_corpus.extend(candidate_sentences)\n",
    "#             if i % 20 == 0:\n",
    "#                 input_sent = ' '.join([train_input_lang.index2word[token.item()] for token in input[ind]])\n",
    "#                 print('input: '+input_sent)\n",
    "            if i % 20 == 0:\n",
    "                print('predict: '+sent_words)\n",
    "                check += 1\n",
    "\n",
    "        reference_sentences = []\n",
    "        for sent in target:\n",
    "            sent_words = []\n",
    "            for token in sent:\n",
    "                if token.item() != EOS_token:\n",
    "                    sent_words.append(train_output_lang.index2word[token.item()])\n",
    "                else:\n",
    "                    break\n",
    "            sent_words = ' '.join(sent_words)\n",
    "            reference_sentences.append(sent_words)\n",
    "#         reference_corpus.extend(reference_sentences)\n",
    "            if i % 20 == 0:\n",
    "                print('target: '+sent_words)\n",
    "                check += 1\n",
    "        \n",
    "        count += 1\n",
    "        score = corpus_bleu(candidate_sentences, [reference_sentences], smooth='exp', smooth_floor=0.0, force=False).score\n",
    "        print('batch {}: bleu: {}'.format(i+1,score))\n",
    "        total_score += score\n",
    "\n",
    "    return total_score / float(count)\n",
    "\n",
    "#     score = corpus_bleu(candidate_sentences, [reference_sentences], smooth='exp', smooth_floor=0.0, force=False).score\n",
    "#     return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: m submarines bizarre lange big earth captured captured captured\n",
      "predict: the submarines bizarre the the the the the the captured\n",
      "predict: us the the the the the the the\n",
      "predict: us submarines bizarre the the the captured captured\n",
      "predict: the submarines bizarre the the the the the the captured captured\n",
      "predict: the submarines bizarre the the the volcanic captured captured\n",
      "predict: m submarines bizarre big the captured captured captured\n",
      "predict: get m submarines bizarre captured\n",
      "predict: the submarines bizarre the the the the the captured captured\n",
      "predict: the submarines bizarre the the the the the the the the captured\n",
      "predict: to submarines some lange the earth the volcanic captured captured captured\n",
      "predict: to submarines some of earth earth earth the volcanic captured captured\n",
      "predict: to submarines habitats valleys earth earth earth the volcanic the captured captured captured\n",
      "predict: get to submarines some animal the volcanic earth the to captured captured\n",
      "predict: hardwired s submarines some of earth\n",
      "predict: to submarines some of earth earth the the volcanic the captured captured\n",
      "predict: landscapes submarines some the the the volcanic the captured captured\n",
      "predict: to submarines some of earth earth captured captured captured\n",
      "predict: to submarines some to captured captured captured captured\n",
      "predict: become to submarines some of earth captured captured\n",
      "predict: to submarines some of earth earth earth captured captured captured captured\n",
      "predict: us produces trials trials trials trials produces trials produces captured captured captured\n",
      "predict: the submarines bizarre the the the the captured captured\n",
      "predict: the submarines volcanic the the the the the the the the the\n",
      "predict: us submarines bizarre the the volcanic captured captured\n",
      "predict: us submarines bizarre\n",
      "predict: produces produces trials trials trials produces trials produces trials captured captured captured\n",
      "predict: the submarines bizarre the the the the the the the captured captured\n",
      "predict: the submarines bizarre the the the the the captured captured\n",
      "predict: the submarines bizarre the the the the captured captured captured\n",
      "predict: the submarines bizarre the the the the the captured captured captured\n",
      "predict: us the submarines s volcanic the the the the the volcanic\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "target: my father was listening to bbc news on his small gray radio .\n",
      "target: there was a big smile on his face which was unusual then because the news mostly depressed him .\n",
      "target: quot the taliban are gone ! quot my father shouted .\n",
      "target: i didn apos t know what it meant but i could see that my father was very very happy .\n",
      "target: quot you can go to a real school now quot he said .\n",
      "target: a morning that i will never forget .\n",
      "target: a real school .\n",
      "target: you see i was six when the taliban took over afghanistan and made it illegal for girls to go to school .\n",
      "target: so for the next five years i dressed as a boy to escort my older sister who was no longer allowed to be outside alone to a secret school .\n",
      "target: it was the only way we both could be educated .\n",
      "target: each day we took a different route so that no one would suspect where we were going .\n",
      "target: we would cover our books in grocery bags so it would seem we were just out shopping .\n",
      "target: the school was in a house more than of us packed in one small living room .\n",
      "target: it was cozy in winter but extremely hot in summer .\n",
      "target: we all knew we were risking our lives the teacher the students and our parents .\n",
      "target: from time to time the school would suddenly be canceled for a week because taliban were suspicious .\n",
      "target: we always wondered what they knew about us .\n",
      "target: were we being followed ?\n",
      "target: do they know where we live ?\n",
      "target: we were scared but still school was where we wanted to be .\n",
      "target: i was very lucky to grow up in a family where education was prized and daughters were treasured .\n",
      "target: my grandfather was an extraordinary man for his time .\n",
      "target: a total maverick from a remote province of afghanistan he insisted that his daughter my mom go to school and for that he was <unk> by his father .\n",
      "target: but my educated mother became a teacher .\n",
      "target: there she is .\n",
      "target: she retired two years ago only to turn our house into a school for girls and women in our neighborhood .\n",
      "target: and my father that apos s him he was the first ever in his family to receive an education .\n",
      "target: there was no question that his children would receive an education including his daughters despite the taliban despite the risks .\n",
      "target: to him there was greater risk in not educating his children .\n",
      "target: during taliban years i remember there were times i would get so frustrated by our life and always being scared and not seeing a future .\n",
      "target: i would want to quit but my father he would say quot listen my daughter you can lose everything you own in your life .\n",
      "batch 1: bleu: 0.14123117618136216\n",
      "batch 2: bleu: 0.10371848937899429\n",
      "batch 3: bleu: 0.12294021959087092\n",
      "batch 4: bleu: 0.12307199775175377\n",
      "batch 5: bleu: 0.14256899296711822\n",
      "batch 6: bleu: 0.1374606154918132\n",
      "batch 7: bleu: 0.11426978903756657\n",
      "batch 8: bleu: 0.13308689955589886\n",
      "batch 9: bleu: 0.0892428906635375\n",
      "batch 10: bleu: 0.11007645978455693\n",
      "batch 11: bleu: 0.08730251994300726\n",
      "batch 12: bleu: 0.08137329110548429\n",
      "batch 13: bleu: 0.09868555239880164\n",
      "batch 14: bleu: 0.09224425743593917\n",
      "batch 15: bleu: 0.18717445268505148\n",
      "batch 16: bleu: 0.14233620623123658\n",
      "batch 17: bleu: 0.12116015670807967\n",
      "batch 18: bleu: 0.138822624738952\n",
      "batch 19: bleu: 0.13365710422893826\n",
      "batch 20: bleu: 0.1444530333895006\n",
      "predict: the submarines bizarre the the the the the the the the captured captured\n",
      "predict: produces submarines trials trials trials considerable waters us produces submarines bizarre captured captured captured captured\n",
      "predict: us submarines bizarre the the volcanic the captured captured\n",
      "predict: produces produces produces produces trials produces produces produces produces trials produces produces\n",
      "predict: produces produces trials trials produces trials produces trials trials captured captured\n",
      "predict: the submarines bizarre the the the captured captured\n",
      "predict: to submarines some of earth earth the captured captured captured\n",
      "predict: to submarines some of earth the in the the the captured captured\n",
      "predict: to submarines some animal earth earth gets gets gets captured captured captured\n",
      "predict: to submarines some of earth earth earth earth to to earth captured captured\n",
      "predict: the submarines bizarre the the the the the the the the captured\n",
      "predict: produces produces trials produces produces trials produces produces trials captured\n",
      "predict: us submarines bizarre the the the captured captured\n",
      "predict: by submarines david of earth earth earth by by captured captured\n",
      "predict: the submarines bizarre the the the the the captured captured captured\n",
      "predict: us the bizarre bizarre volcanic the earth the by by the captured\n",
      "predict: produces produces produces produces trials produces produces produces produces captured captured\n",
      "predict: us submarines bizarre the the the the captured\n",
      "predict: us submarines bizarre the the the volcanic captured captured\n",
      "predict: by submarines david of earth earth the volcanic the captured captured\n",
      "predict: with vibrant big blue volcanic the the the the\n",
      "predict: us the submarines bizarre the volcanic in the the the the the the the the the the the\n",
      "predict: to submarines some big big the volcanic earth the earth the earth the earth the earth the\n",
      "predict: us to submarines some of earth captured captured captured\n",
      "predict: us submarines bizarre the earth captured captured captured\n",
      "predict: produces produces bizarre trials produces trials produces trials earth captured captured\n",
      "predict: the submarines the the the the the the the captured captured\n",
      "predict: the submarines volcanic to the volcanic hiding volcanic the earth earth the hiding volcanic earth the earth the earth the\n",
      "predict: the submarines bizarre the the the the the earth captured captured captured\n",
      "predict: produces produces trials trials trials trials trials trials trials trials trials trials captured captured captured captured\n",
      "predict: to submarines habitats valleys big pills allow in the shimmering captured\n",
      "predict: the submarines volcanic by by submarines volcanic by by the earth the earth the by the earth\n",
      "target: soon after an organization i volunteer with all hands volunteers were on the ground within days working as part of the response efforts .\n",
      "target: i along with hundreds of other volunteers knew we couldn apos t just sit at home so i decided to join them for three weeks .\n",
      "target: on may the th i made my way to the town of <unk> .\n",
      "target: it apos s a small fishing town in <unk> prefecture about people one of the first that was hit by the wave .\n",
      "target: the waters here have been recorded at reaching over meters in height and traveled over two miles inland .\n",
      "target: as you can imagine the town had been devastated .\n",
      "target: we pulled debris from canals and ditches .\n",
      "target: we cleaned schools . we de <unk> and gutted homes ready for renovation and rehabilitation .\n",
      "target: we cleared tons and tons of stinking rotting fish carcasses from the local fish processing plant .\n",
      "target: we got dirty and we loved it .\n",
      "target: for weeks all the volunteers and locals alike had been finding similar things .\n",
      "target: they apos d been finding photos and photo albums and cameras and sd cards .\n",
      "target: and everyone was doing the same .\n",
      "target: they were collecting them up and handing them in to various places around the different towns for <unk> .\n",
      "target: now it wasn apos t until this point that i realized that these photos were such a huge part of the personal loss these people had felt .\n",
      "target: as they had run from the wave and for their lives absolutely everything they had everything had to be left behind .\n",
      "target: at the end of my first week there i found myself helping out in an evacuation center in the town .\n",
      "target: i was helping clean the <unk> the communal <unk> the huge giant <unk> .\n",
      "target: this happened to also be a place in the town where the evacuation center was collecting the photos .\n",
      "target: this is where people were handing them in and i was honored that day that they actually trusted me to help them start hand cleaning them .\n",
      "target: now it was emotional and it was inspiring and i apos ve always heard about thinking outside the box but it wasn apos t until i had actually gotten outside of my box that something happened .\n",
      "target: as i looked through the photos there were some were over a hundred years old some still in the envelope from the processing lab i couldn apos t help but think as a <unk> that i could fix that tear\n",
      "target: so that evening i just reached out on facebook and asked a few of them and by morning the response had been so overwhelming and so positive i knew we had to give it a go .\n",
      "target: so we started <unk> photos .\n",
      "target: this was the very first .\n",
      "target: not terribly damaged but where the water had caused that <unk> on the girl apos s face had to be repaired with such accuracy and delicacy .\n",
      "target: otherwise that little girl isn apos t going to look like that little girl anymore and surely that apos s as tragic as having the photo damaged .\n",
      "target: over time more photos came in thankfully and more retouchers were needed and so i reached out again on facebook and linkedin and within five days people wanted to help from different countries .\n",
      "target: within two weeks i had people wanting to join in .\n",
      "target: within japan by july we apos d branched out to the neighboring town of <unk> further north to a town called <unk> .\n",
      "target: once a week we would set up our scanning equipment in the temporary photo libraries that had been set up where people were reclaiming their photos .\n",
      "target: the older ladies sometimes hadn apos t seen a scanner before but within minutes of them finding their lost photo they could give it to us have it scanned uploaded to a cloud server it would be downloaded by a\n",
      "batch 21: bleu: 0.21815323297305297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 22: bleu: 0.12591854302765146\n",
      "batch 23: bleu: 0.10199104658234201\n",
      "batch 24: bleu: 0.08889222036908966\n",
      "batch 25: bleu: 0.10508610322666333\n",
      "batch 26: bleu: 0.12327139014581195\n",
      "batch 27: bleu: 0.1129226399275569\n",
      "batch 28: bleu: 0.11091220140580191\n",
      "batch 29: bleu: 0.11342733507495625\n",
      "batch 30: bleu: 0.1200610555414891\n",
      "batch 31: bleu: 0.12259024916341915\n",
      "batch 32: bleu: 0.17780114766473706\n",
      "batch 33: bleu: 0.10454691228489726\n",
      "batch 34: bleu: 0.08041177840733403\n",
      "batch 35: bleu: 0.10092450598329217\n",
      "batch 36: bleu: 0.11306688865727357\n",
      "batch 37: bleu: 0.08009273840678621\n",
      "batch 38: bleu: 0.11597295158093461\n",
      "batch 39: bleu: 0.09587407112735168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1194049677133052"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_val(cnn_en,cnn_de,val_loader,encoder_cnn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "target: when i was i remember waking up one morning to the sound of joy in my house .\n",
      "target: my father was listening to bbc news on his small gray radio .\n",
      "target: there was a big smile on his face which was unusual then because the news mostly depressed him .\n",
      "target: quot the taliban are gone ! quot my father shouted .\n",
      "target: i didn apos t know what it meant but i could see that my father was very very happy .\n",
      "target: quot you can go to a real school now quot he said .\n",
      "target: a morning that i will never forget .\n",
      "target: a real school .\n",
      "target: you see i was six when the taliban took over afghanistan and made it illegal for girls to go to school .\n",
      "target: so for the next five years i dressed as a boy to escort my older sister who was no longer allowed to be outside alone to a secret school .\n",
      "target: it was the only way we both could be educated .\n",
      "target: each day we took a different route so that no one would suspect where we were going .\n",
      "target: we would cover our books in grocery bags so it would seem we were just out shopping .\n",
      "target: the school was in a house more than of us packed in one small living room .\n",
      "target: it was cozy in winter but extremely hot in summer .\n",
      "target: we all knew we were risking our lives the teacher the students and our parents .\n",
      "target: from time to time the school would suddenly be canceled for a week because taliban were suspicious .\n",
      "target: we always wondered what they knew about us .\n",
      "target: were we being followed ?\n",
      "target: do they know where we live ?\n",
      "target: we were scared but still school was where we wanted to be .\n",
      "target: i was very lucky to grow up in a family where education was prized and daughters were treasured .\n",
      "target: my grandfather was an extraordinary man for his time .\n",
      "target: a total maverick from a remote province of afghanistan he insisted that his daughter my mom go to school and for that he was <unk> by his father .\n",
      "target: but my educated mother became a teacher .\n",
      "target: there she is .\n",
      "target: she retired two years ago only to turn our house into a school for girls and women in our neighborhood .\n",
      "target: and my father that apos s him he was the first ever in his family to receive an education .\n",
      "target: there was no question that his children would receive an education including his daughters despite the taliban despite the risks .\n",
      "target: to him there was greater risk in not educating his children .\n",
      "target: during taliban years i remember there were times i would get so frustrated by our life and always being scared and not seeing a future .\n",
      "target: i would want to quit but my father he would say quot listen my daughter you can lose everything you own in your life .\n",
      "batch 1: bleu: 0.49096048123730085\n",
      "batch 2: bleu: 0.3939004020449434\n",
      "batch 3: bleu: 0.8617070713886422\n",
      "batch 4: bleu: 0.5041387990265633\n",
      "batch 5: bleu: 1.156053426610965\n",
      "batch 6: bleu: 0.9132737718555536\n",
      "batch 7: bleu: 0.6303381844163454\n",
      "batch 8: bleu: 0.5636224973993404\n",
      "batch 9: bleu: 1.079071789614086\n",
      "batch 10: bleu: 2.476928242868487\n",
      "batch 11: bleu: 0.9545183348898235\n",
      "batch 12: bleu: 1.261693182786175\n",
      "batch 13: bleu: 0.7326649054486112\n",
      "batch 14: bleu: 0.5948577203122039\n",
      "batch 15: bleu: 0.6777762127028494\n",
      "batch 16: bleu: 0.9456560627023767\n",
      "batch 17: bleu: 1.9658038142674101\n",
      "batch 18: bleu: 1.7121587607418256\n",
      "batch 19: bleu: 2.7173620584948073\n",
      "batch 20: bleu: 1.153589126496657\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "predict: and i apos m going to be a lot of the world .\n",
      "target: soon after an organization i volunteer with all hands volunteers were on the ground within days working as part of the response efforts .\n",
      "target: i along with hundreds of other volunteers knew we couldn apos t just sit at home so i decided to join them for three weeks .\n",
      "target: on may the th i made my way to the town of <unk> .\n",
      "target: it apos s a small fishing town in <unk> prefecture about people one of the first that was hit by the wave .\n",
      "target: the waters here have been recorded at reaching over meters in height and traveled over two miles inland .\n",
      "target: as you can imagine the town had been devastated .\n",
      "target: we pulled debris from canals and ditches .\n",
      "target: we cleaned schools . we de <unk> and gutted homes ready for renovation and rehabilitation .\n",
      "target: we cleared tons and tons of stinking rotting fish carcasses from the local fish processing plant .\n",
      "target: we got dirty and we loved it .\n",
      "target: for weeks all the volunteers and locals alike had been finding similar things .\n",
      "target: they apos d been finding photos and photo albums and cameras and sd cards .\n",
      "target: and everyone was doing the same .\n",
      "target: they were collecting them up and handing them in to various places around the different towns for <unk> .\n",
      "target: now it wasn apos t until this point that i realized that these photos were such a huge part of the personal loss these people had felt .\n",
      "target: as they had run from the wave and for their lives absolutely everything they had everything had to be left behind .\n",
      "target: at the end of my first week there i found myself helping out in an evacuation center in the town .\n",
      "target: i was helping clean the <unk> the communal <unk> the huge giant <unk> .\n",
      "target: this happened to also be a place in the town where the evacuation center was collecting the photos .\n",
      "target: this is where people were handing them in and i was honored that day that they actually trusted me to help them start hand cleaning them .\n",
      "target: now it was emotional and it was inspiring and i apos ve always heard about thinking outside the box but it wasn apos t until i had actually gotten outside of my box that something happened .\n",
      "target: as i looked through the photos there were some were over a hundred years old some still in the envelope from the processing lab i couldn apos t help but think as a <unk> that i could fix that tear\n",
      "target: so that evening i just reached out on facebook and asked a few of them and by morning the response had been so overwhelming and so positive i knew we had to give it a go .\n",
      "target: so we started <unk> photos .\n",
      "target: this was the very first .\n",
      "target: not terribly damaged but where the water had caused that <unk> on the girl apos s face had to be repaired with such accuracy and delicacy .\n",
      "target: otherwise that little girl isn apos t going to look like that little girl anymore and surely that apos s as tragic as having the photo damaged .\n",
      "target: over time more photos came in thankfully and more retouchers were needed and so i reached out again on facebook and linkedin and within five days people wanted to help from different countries .\n",
      "target: within two weeks i had people wanting to join in .\n",
      "target: within japan by july we apos d branched out to the neighboring town of <unk> further north to a town called <unk> .\n",
      "target: once a week we would set up our scanning equipment in the temporary photo libraries that had been set up where people were reclaiming their photos .\n",
      "target: the older ladies sometimes hadn apos t seen a scanner before but within minutes of them finding their lost photo they could give it to us have it scanned uploaded to a cloud server it would be downloaded by a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 21: bleu: 0.7090420408048385\n",
      "batch 22: bleu: 0.47676412889722\n",
      "batch 23: bleu: 2.0270913893564497\n",
      "batch 24: bleu: 0.371090549424509\n",
      "batch 25: bleu: 1.067189592769331\n",
      "batch 26: bleu: 1.1906195417586753\n",
      "batch 27: bleu: 0.7621629074750933\n",
      "batch 28: bleu: 1.0430932182527446\n",
      "batch 29: bleu: 1.3534049587438952\n",
      "batch 30: bleu: 1.1687269055231078\n",
      "batch 31: bleu: 1.0057984051085882\n",
      "batch 32: bleu: 0.9683688958798589\n",
      "batch 33: bleu: 1.045485361533528\n",
      "batch 34: bleu: 0.41718143946528957\n",
      "batch 35: bleu: 0.4990749788577744\n",
      "batch 36: bleu: 0.7737583152500009\n",
      "batch 37: bleu: 0.5667263889375768\n",
      "batch 38: bleu: 0.4541978565349855\n",
      "batch 39: bleu: 0.936236091090201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9903099438709904"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_val(en,de,val_loader,encoder_cnn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
